{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7f3f6729",
      "metadata": {},
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "90820bed",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport pyodbc\nfrom tqdm import tqdm \nfrom datetime import date, datetime\nimport unicodedata\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\nfrom sklearn.utils import compute_class_weight\nimport joblib\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport shap"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f2213d3",
      "metadata": {},
      "source": [
        "#### Base estudiantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1532e0f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\2106066819.py:77: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_inicial = pd.read_sql(query_inicial, conn)\n"
          ]
        }
      ],
      "source": [
        "# Conexión\nserver = '172.16.1.33'\ndatabase = 'CUN_REPOSITORIO'\n\ntry:\n    conn = pyodbc.connect(\n        'DRIVER={ODBC Driver 17 for SQL Server};'\n        f'SERVER={server};'\n        f'DATABASE={database};'\n        'Trusted_Connection=yes;'\n    )\n\n    # Tabla principal\n    query_inicial = \"\"\"\nWITH Ultima_Liquidacion AS (\n    SELECT \n        Identificacion,\n        MAX(Fecha_Liquidacion) AS Ultima_Fecha\n    FROM Desercion.Resultado_Final_CUN\n    WHERE Fecha_Liquidacion < '2025-07-01'\n    GROUP BY Identificacion\n)\nSELECT \n    rf.Identificacion AS Identificacion,\n    rf.Periodo AS Periodo,\n    rf.Status AS DescRF_Status,\n    rf.Tipo_estado_alumno AS DescRF_Tipo_estado_alumno,\n    rf.Modalidad AS DescRF_Modalidad,\n    rf.Semestre_SINU AS DescRF_Semestre_SINU,\n    rf.ciclo AS DescRF_ciclo,\n    rf.SEMESTRE_MEN AS DescRF_SEMESTRE_MEN,\n    rf.Genero AS DescRF_Genero,\n    rf.Unidad AS DescRF_Unidad,\n    rf.Jornada AS DescRF_Jornada,\n    rf.Periodo_Ult_Pago AS DescRF_Periodo_Ult_Pago,\n    rf.Sede AS DescRF_Sede,\n    rf.Regional AS DescRF_Regional,\n    rf.Programa AS DescRF_Programa,\n    rf.Acceso_Moodle AS DescRF_Acceso_Moodle,\n    rf.tipo_estudio AS DescRF_tipo_estudio,\n    rf.Id_Alumn_Programa AS Id_Alumn_Programa,\n    rf.Tipo_Alumno AS DescRF_Tipo_Alumno,\n    rf.Nuevo AS DescRF_Nuevo,\n    rf.orden AS DescRF_orden,\n    rf.Fecha_Liquidacion AS DescRF_Fecha_Liquidacion,\n    rf.Fecha_Nacimiento AS DescRF_Fecha_Nacimiento,\n    rf.ultimo_curso AS DescRF_ultimo_curso,\n    dm.[MATERIAS INSCRITAS] AS DescAM_MATERIAS_INSCRITAS,\n    dm.[MATERIAS APROBADAS] AS DescAM_MATERIAS_APROBADAS,\n    dm.[Porcentaje_aprobacion] AS DescAM_Porcentaje_aprobacion,\n    ee.promedio as EEpromedio,\n    ee.UNIDADNEGOCIO AS EE_UNIDADNEGOCIO,\n    ee.DEPARTAMENTO_REGIONAL AS EE_DEPARTAMENTO_REGIONAL,\n    ee.OTRA_DISCAPACIDAD AS EE_OTRA_DISCAPACIDAD,\n    ee.SISTEMA_SALUD AS EE_SISTEMA_SALUD,\n    ee.ESTRATO_ACTUALIZADO AS EE_ESTRATO_ACTUALIZADO,\n    ee.EMPRESA AS EE_EMPRESA\nFROM Desercion.Resultado_Final_CUN rf\nJOIN Ultima_Liquidacion ul \n    ON rf.Identificacion = ul.Identificacion \n   AND rf.Fecha_Liquidacion = ul.Ultima_Fecha\nJOIN Desercion.PORCENTAJE_APROBACION_MATERIAS dm  \n    ON rf.Identificacion = dm.IDENTIFICACION \n   AND rf.Periodo = dm.COD_PERIODO\nLEFT JOIN CUN.ESTADISTICA_ESTUDIANTE_2 AS ee  \n    ON rf.Identificacion = ee.NUM_IDENTIFICACION \n   AND rf.Periodo = ee.COD_PERIODO\nLEFT JOIN Financiera.Recibos_caja AS rc \n    ON rf.Identificacion = CONVERT(VARCHAR(20), rc.cliente) \n   AND rc.periodo = rf.Periodo\nLEFT JOIN CUN.Zoho_Sinu AS zz  \n    ON rf.Identificacion = zz.NUM_IDENTIFICACION\nLEFT JOIN Financiera.Recibos_Caja_Medios_Pago AS mp \n    ON rf.Identificacion = mp.IDENTIFICACION \n   AND rf.periodo = mp.PERIODO;\n      \"\"\"\n    df_inicial = pd.read_sql(query_inicial, conn)\n\n    # Cerrar conexión \n    conn.close()\n\nexcept Exception as e:\n    print(\"Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6e6c448e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Identificacion</th>\n",
              "      <th>Periodo</th>\n",
              "      <th>DescRF_Status</th>\n",
              "      <th>DescRF_Tipo_estado_alumno</th>\n",
              "      <th>DescRF_Modalidad</th>\n",
              "      <th>DescRF_Semestre_SINU</th>\n",
              "      <th>DescRF_ciclo</th>\n",
              "      <th>DescRF_SEMESTRE_MEN</th>\n",
              "      <th>DescRF_Genero</th>\n",
              "      <th>DescRF_Unidad</th>\n",
              "      <th>...</th>\n",
              "      <th>DescAM_MATERIAS_INSCRITAS</th>\n",
              "      <th>DescAM_MATERIAS_APROBADAS</th>\n",
              "      <th>DescAM_Porcentaje_aprobacion</th>\n",
              "      <th>EEpromedio</th>\n",
              "      <th>EE_UNIDADNEGOCIO</th>\n",
              "      <th>EE_DEPARTAMENTO_REGIONAL</th>\n",
              "      <th>EE_OTRA_DISCAPACIDAD</th>\n",
              "      <th>EE_SISTEMA_SALUD</th>\n",
              "      <th>EE_ESTRATO_ACTUALIZADO</th>\n",
              "      <th>EE_EMPRESA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00010105021</td>\n",
              "      <td>2017B</td>\n",
              "      <td>Desercion CUN</td>\n",
              "      <td>NUEVO</td>\n",
              "      <td>Presencial</td>\n",
              "      <td>1</td>\n",
              "      <td>TECNICO</td>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>Técnica Profesional en Logística de Comercio E...</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>80.00</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00010308259</td>\n",
              "      <td>2018A</td>\n",
              "      <td>Desercion CUN</td>\n",
              "      <td>ANTIGUO</td>\n",
              "      <td>Presencial</td>\n",
              "      <td>2</td>\n",
              "      <td>TECNICO</td>\n",
              "      <td>1</td>\n",
              "      <td>F</td>\n",
              "      <td>Técnica Profesional en Logística de Comercio E...</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>100.00</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00010606926</td>\n",
              "      <td>2017A</td>\n",
              "      <td>Desercion CUN</td>\n",
              "      <td>NUEVO</td>\n",
              "      <td>Presencial</td>\n",
              "      <td>1</td>\n",
              "      <td>TECNICO</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>TÉCNICA PROFESIONAL EN SERVICIOS TURÍSTICOS Y ...</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>57.14</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00011104070</td>\n",
              "      <td>2018A</td>\n",
              "      <td>Desercion CUN</td>\n",
              "      <td>ANTIGUO</td>\n",
              "      <td>Presencial</td>\n",
              "      <td>2</td>\n",
              "      <td>TECNICO</td>\n",
              "      <td>1</td>\n",
              "      <td>F</td>\n",
              "      <td>TECNICA PROFESIONAL EN PROCESOS GRAFICOS</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>11.11</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00011206301</td>\n",
              "      <td>2017B</td>\n",
              "      <td>Desercion CUN</td>\n",
              "      <td>NUEVO</td>\n",
              "      <td>Distancia</td>\n",
              "      <td>1</td>\n",
              "      <td>TECNICO</td>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>TECNICA PROFESIONAL EN PROCESOS ADMINISTRATIVOS</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>88.89</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176908</th>\n",
              "      <td>9976845</td>\n",
              "      <td>2025A</td>\n",
              "      <td>Rematriculado</td>\n",
              "      <td>ANTIGUO</td>\n",
              "      <td>Presencial</td>\n",
              "      <td>6</td>\n",
              "      <td>PROFESIONAL</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>TÉCNICA PROFESIONAL EN SERVICIOS ADMINISTRATIV...</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176909</th>\n",
              "      <td>9976918</td>\n",
              "      <td>2017A</td>\n",
              "      <td>Graduado</td>\n",
              "      <td>ANTIGUO</td>\n",
              "      <td>Distancia</td>\n",
              "      <td>10</td>\n",
              "      <td>PROFESIONAL</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>Técnica Profesional en Contabilidad y Finanzas</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>100.00</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176910</th>\n",
              "      <td>9977464</td>\n",
              "      <td>22V01</td>\n",
              "      <td>Desercion CUN</td>\n",
              "      <td>Nuevo - Homologado</td>\n",
              "      <td>Virtual</td>\n",
              "      <td>2</td>\n",
              "      <td>TECNICO</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>TÉCNICA PROFESIONAL EN REGISTRO DE PROCESOS PR...</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>100.00</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176911</th>\n",
              "      <td>9977702</td>\n",
              "      <td>21V06</td>\n",
              "      <td>Retiro</td>\n",
              "      <td>Nuevo - Homologado</td>\n",
              "      <td>Virtual</td>\n",
              "      <td>7</td>\n",
              "      <td>PROFESIONAL</td>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>TÉCNICA PROFESIONAL EN ADMINISTRACIÓN DE PROCE...</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176912</th>\n",
              "      <td>9994800</td>\n",
              "      <td>2016A</td>\n",
              "      <td>Graduado</td>\n",
              "      <td>ANTIGUO</td>\n",
              "      <td>Presencial</td>\n",
              "      <td>10</td>\n",
              "      <td>PROFESIONAL</td>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>Negocios Internacionales</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>100.00</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>176913 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Identificacion Periodo  DescRF_Status DescRF_Tipo_estado_alumno  \\\n",
              "0         00010105021   2017B  Desercion CUN                     NUEVO   \n",
              "1         00010308259   2018A  Desercion CUN                   ANTIGUO   \n",
              "2         00010606926   2017A  Desercion CUN                     NUEVO   \n",
              "3         00011104070   2018A  Desercion CUN                   ANTIGUO   \n",
              "4         00011206301   2017B  Desercion CUN                     NUEVO   \n",
              "...               ...     ...            ...                       ...   \n",
              "176908        9976845   2025A  Rematriculado                   ANTIGUO   \n",
              "176909        9976918   2017A       Graduado                   ANTIGUO   \n",
              "176910        9977464   22V01  Desercion CUN        Nuevo - Homologado   \n",
              "176911        9977702   21V06         Retiro        Nuevo - Homologado   \n",
              "176912        9994800   2016A       Graduado                   ANTIGUO   \n",
              "\n",
              "       DescRF_Modalidad  DescRF_Semestre_SINU DescRF_ciclo  \\\n",
              "0            Presencial                     1      TECNICO   \n",
              "1            Presencial                     2      TECNICO   \n",
              "2            Presencial                     1      TECNICO   \n",
              "3            Presencial                     2      TECNICO   \n",
              "4             Distancia                     1      TECNICO   \n",
              "...                 ...                   ...          ...   \n",
              "176908       Presencial                     6  PROFESIONAL   \n",
              "176909        Distancia                    10  PROFESIONAL   \n",
              "176910          Virtual                     2      TECNICO   \n",
              "176911          Virtual                     7  PROFESIONAL   \n",
              "176912       Presencial                    10  PROFESIONAL   \n",
              "\n",
              "       DescRF_SEMESTRE_MEN DescRF_Genero  \\\n",
              "0                        2             M   \n",
              "1                        1             F   \n",
              "2                        1             M   \n",
              "3                        1             F   \n",
              "4                        2             M   \n",
              "...                    ...           ...   \n",
              "176908                   1             M   \n",
              "176909                   1             M   \n",
              "176910                   1             M   \n",
              "176911                   2             M   \n",
              "176912                   1             M   \n",
              "\n",
              "                                            DescRF_Unidad  ...  \\\n",
              "0       Técnica Profesional en Logística de Comercio E...  ...   \n",
              "1       Técnica Profesional en Logística de Comercio E...  ...   \n",
              "2       TÉCNICA PROFESIONAL EN SERVICIOS TURÍSTICOS Y ...  ...   \n",
              "3                TECNICA PROFESIONAL EN PROCESOS GRAFICOS  ...   \n",
              "4        TECNICA PROFESIONAL EN PROCESOS ADMINISTRATIVOS   ...   \n",
              "...                                                   ...  ...   \n",
              "176908  TÉCNICA PROFESIONAL EN SERVICIOS ADMINISTRATIV...  ...   \n",
              "176909     Técnica Profesional en Contabilidad y Finanzas  ...   \n",
              "176910  TÉCNICA PROFESIONAL EN REGISTRO DE PROCESOS PR...  ...   \n",
              "176911  TÉCNICA PROFESIONAL EN ADMINISTRACIÓN DE PROCE...  ...   \n",
              "176912                           Negocios Internacionales  ...   \n",
              "\n",
              "       DescAM_MATERIAS_INSCRITAS DescAM_MATERIAS_APROBADAS  \\\n",
              "0                             10                         8   \n",
              "1                              7                         7   \n",
              "2                              7                         4   \n",
              "3                              9                         1   \n",
              "4                              9                         8   \n",
              "...                          ...                       ...   \n",
              "176908                         7                         0   \n",
              "176909                         7                         7   \n",
              "176910                         8                         8   \n",
              "176911                         7                         0   \n",
              "176912                         3                         3   \n",
              "\n",
              "       DescAM_Porcentaje_aprobacion EEpromedio EE_UNIDADNEGOCIO  \\\n",
              "0                             80.00       None             None   \n",
              "1                            100.00       None             None   \n",
              "2                             57.14       None             None   \n",
              "3                             11.11       None             None   \n",
              "4                             88.89       None             None   \n",
              "...                             ...        ...              ...   \n",
              "176908                         0.00       None             None   \n",
              "176909                       100.00       None             None   \n",
              "176910                       100.00       None             None   \n",
              "176911                         0.00       None             None   \n",
              "176912                       100.00       None             None   \n",
              "\n",
              "       EE_DEPARTAMENTO_REGIONAL EE_OTRA_DISCAPACIDAD  EE_SISTEMA_SALUD  \\\n",
              "0                          None                 None              None   \n",
              "1                          None                 None              None   \n",
              "2                          None                 None              None   \n",
              "3                          None                 None              None   \n",
              "4                          None                 None              None   \n",
              "...                         ...                  ...               ...   \n",
              "176908                     None                 None              None   \n",
              "176909                     None                 None              None   \n",
              "176910                     None                 None              None   \n",
              "176911                     None                 None              None   \n",
              "176912                     None                 None              None   \n",
              "\n",
              "       EE_ESTRATO_ACTUALIZADO EE_EMPRESA  \n",
              "0                        None       None  \n",
              "1                        None       None  \n",
              "2                        None       None  \n",
              "3                        None       None  \n",
              "4                        None       None  \n",
              "...                       ...        ...  \n",
              "176908                   None       None  \n",
              "176909                   None       None  \n",
              "176910                   None       None  \n",
              "176911                   None       None  \n",
              "176912                   None       None  \n",
              "\n",
              "[176913 rows x 34 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66acb45c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final_final['Tipo_estado_alumno'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0567f7f1",
      "metadata": {},
      "source": [
        "#### Notas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c51a43c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Descargando por periodo:   0%|          | 0/101 [00:00<?, ?it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:   1%|          | 1/101 [00:01<02:24,  1.45s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:   2%|▏         | 2/101 [00:01<01:07,  1.46it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:   3%|▎         | 3/101 [00:02<01:06,  1.47it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:   4%|▍         | 4/101 [00:02<00:48,  2.00it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:   5%|▍         | 5/101 [00:02<00:38,  2.49it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:   6%|▌         | 6/101 [00:04<01:13,  1.29it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:   7%|▋         | 7/101 [00:04<01:11,  1.31it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:   8%|▊         | 8/101 [00:05<01:03,  1.47it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:   9%|▉         | 9/101 [00:06<01:24,  1.09it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  10%|▉         | 10/101 [00:07<01:21,  1.12it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  11%|█         | 11/101 [00:08<01:07,  1.32it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  12%|█▏        | 12/101 [00:08<01:02,  1.43it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  14%|█▍        | 14/101 [00:38<10:27,  7.21s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  15%|█▍        | 15/101 [00:57<14:32, 10.14s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  17%|█▋        | 17/101 [00:57<08:19,  5.95s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  18%|█▊        | 18/101 [01:16<12:27,  9.01s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  19%|█▉        | 19/101 [01:33<14:52, 10.89s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  20%|█▉        | 20/101 [01:52<17:36, 13.05s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  21%|██        | 21/101 [02:15<21:05, 15.82s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  22%|██▏       | 22/101 [02:38<23:29, 17.84s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  23%|██▎       | 23/101 [03:02<25:14, 19.41s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  24%|██▍       | 24/101 [05:11<1:05:40, 51.18s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  25%|██▍       | 25/101 [05:52<1:01:09, 48.29s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  26%|██▌       | 26/101 [06:07<47:59, 38.40s/it]  C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  27%|██▋       | 27/101 [06:27<40:35, 32.91s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  28%|██▊       | 28/101 [06:47<35:20, 29.04s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  29%|██▊       | 29/101 [07:07<31:56, 26.62s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  30%|██▉       | 30/101 [07:26<28:34, 24.14s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  31%|███       | 31/101 [07:42<25:28, 21.83s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  32%|███▏      | 32/101 [07:57<22:48, 19.83s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  33%|███▎      | 33/101 [08:14<21:21, 18.84s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  34%|███▎      | 34/101 [08:44<24:57, 22.35s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  35%|███▍      | 35/101 [08:45<17:15, 15.69s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  36%|███▌      | 36/101 [08:45<11:57, 11.04s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  37%|███▋      | 37/101 [08:45<08:16,  7.76s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  38%|███▊      | 38/101 [08:46<06:09,  5.87s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  39%|███▊      | 39/101 [08:47<04:31,  4.38s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  40%|███▉      | 40/101 [08:48<03:19,  3.27s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  41%|████      | 41/101 [08:55<04:26,  4.44s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  42%|████▏     | 42/101 [08:58<04:01,  4.09s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  43%|████▎     | 43/101 [09:00<03:23,  3.52s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  44%|████▎     | 44/101 [09:01<02:22,  2.49s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  45%|████▍     | 45/101 [09:01<01:39,  1.78s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  47%|████▋     | 47/101 [09:01<00:54,  1.00s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  48%|████▊     | 48/101 [09:01<00:43,  1.21it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  49%|████▊     | 49/101 [09:07<01:50,  2.12s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  50%|████▉     | 50/101 [09:13<02:43,  3.20s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  50%|█████     | 51/101 [09:21<03:44,  4.49s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  51%|█████▏    | 52/101 [09:41<07:11,  8.82s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  52%|█████▏    | 53/101 [09:48<06:42,  8.38s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  53%|█████▎    | 54/101 [09:57<06:42,  8.56s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  54%|█████▍    | 55/101 [09:57<04:40,  6.10s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  56%|█████▋    | 57/101 [09:57<02:28,  3.37s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  57%|█████▋    | 58/101 [09:58<01:53,  2.65s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  58%|█████▊    | 59/101 [09:58<01:25,  2.04s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  59%|█████▉    | 60/101 [09:58<01:04,  1.57s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  60%|██████    | 61/101 [10:20<04:50,  7.27s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  61%|██████▏   | 62/101 [10:40<06:56, 10.67s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  62%|██████▏   | 63/101 [10:52<07:01, 11.09s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  63%|██████▎   | 64/101 [12:11<19:05, 30.96s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  64%|██████▍   | 65/101 [12:27<15:57, 26.61s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  65%|██████▌   | 66/101 [12:36<12:30, 21.43s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  66%|██████▋   | 67/101 [12:36<08:36, 15.20s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  67%|██████▋   | 68/101 [12:37<05:54, 10.73s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  68%|██████▊   | 69/101 [12:37<04:03,  7.62s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  69%|██████▉   | 70/101 [12:37<02:47,  5.41s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  70%|███████   | 71/101 [12:38<01:56,  3.87s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  71%|███████▏  | 72/101 [12:38<01:20,  2.76s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  72%|███████▏  | 73/101 [13:08<05:08, 11.01s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  73%|███████▎  | 74/101 [13:19<04:59, 11.09s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  74%|███████▍  | 75/101 [13:32<05:02, 11.64s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  75%|███████▌  | 76/101 [13:58<06:40, 16.03s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  76%|███████▌  | 77/101 [14:14<06:19, 15.79s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  77%|███████▋  | 78/101 [14:28<05:49, 15.21s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  78%|███████▊  | 79/101 [14:28<03:56, 10.76s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  79%|███████▉  | 80/101 [14:28<02:40,  7.65s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  80%|████████  | 81/101 [14:29<01:52,  5.61s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  81%|████████  | 82/101 [14:30<01:21,  4.27s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  82%|████████▏ | 83/101 [14:31<00:58,  3.27s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  83%|████████▎ | 84/101 [14:32<00:44,  2.59s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  84%|████████▍ | 85/101 [14:32<00:29,  1.87s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  85%|████████▌ | 86/101 [14:33<00:20,  1.37s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  86%|████████▌ | 87/101 [14:33<00:14,  1.06s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  87%|████████▋ | 88/101 [14:33<00:11,  1.18it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  88%|████████▊ | 89/101 [14:34<00:07,  1.53it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  89%|████████▉ | 90/101 [14:34<00:05,  1.94it/s]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  90%|█████████ | 91/101 [15:05<01:36,  9.62s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  91%|█████████ | 92/101 [15:22<01:46, 11.87s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  92%|█████████▏| 93/101 [15:35<01:39, 12.45s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  93%|█████████▎| 94/101 [16:06<02:04, 17.72s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  94%|█████████▍| 95/101 [16:24<01:47, 17.94s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  95%|█████████▌| 96/101 [16:40<01:26, 17.35s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  96%|█████████▌| 97/101 [16:41<00:49, 12.40s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  97%|█████████▋| 98/101 [16:42<00:27,  9.08s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  98%|█████████▊| 99/101 [16:42<00:12,  6.39s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo:  99%|█████████▉| 100/101 [17:39<00:21, 21.59s/it]C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\470199164.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_chunk = pd.read_sql(query_chunk, conn)\n",
            "Descargando por periodo: 100%|██████████| 101/101 [18:34<00:00, 11.03s/it]\n"
          ]
        }
      ],
      "source": [
        "# Conexión\nserver = '172.16.1.33'\ndatabase = 'CUN_REPOSITORIO'\n\nconn = pyodbc.connect(\n    'DRIVER={ODBC Driver 17 for SQL Server};'\n    f'SERVER={server};'\n    f'DATABASE={database};'\n    'Trusted_Connection=yes;'\n)\n\n# Lotes\nids_periodos = df_inicial[['Id_Alumn_Programa', 'Periodo']].drop_duplicates()\n\ndf_notas_total = pd.DataFrame()\n\n# Iterar por periodo\nfor periodo, subdf in tqdm(ids_periodos.groupby('Periodo'), desc=\"Descargando por periodo\"):\n    ids = subdf['Id_Alumn_Programa'].astype(str).tolist()\n\n    # dividir en lotes para que el IN no sea demasiado largo\n    chunk_size = 500  \n    for i in range(0, len(ids), chunk_size):\n        ids_chunk = ids[i:i+chunk_size]\n\n    \n        ids_escaped = [id_.replace(\"'\", \"''''\") for id_ in ids_chunk]\n        ids_str = \",\".join([f\"''{id_}''\" for id_ in ids_escaped])\n\n        query_chunk = f\"\"\"\n        SELECT *\n        FROM OPENQUERY([172.16.1.175], '\n            SELECT \n                ID_ALUM_PROGRAMA,\n                COD_MATERIA,\n                COD_PERIODO,\n                DEF_HISTORIA,\n                NOT_PERIODO\n            FROM SRC_HIS_ACADEMICA\n            WHERE COD_PERIODO=''{periodo}''\n              AND ID_ALUM_PROGRAMA IN ({ids_str})\n        ') AS n\n        \"\"\"\n\n        df_chunk = pd.read_sql(query_chunk, conn)\n        df_notas_total = pd.concat([df_notas_total, df_chunk], ignore_index=True)\n\n# Cerrar conexión\nconn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc6f322",
      "metadata": {},
      "source": [
        "#### Asistencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "940ae374",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Conexión\n# conn = pyodbc.connect(\n#     'DRIVER={ODBC Driver 17 for SQL Server};'\n#     f'SERVER={server};'\n#     f'DATABASE={database};'\n#     'Trusted_Connection=yes;'\n# )\n\n# # Tabla notas\n# query_asistencia = \"\"\"\n#     SELECT \n#         AESPA_IDENTIFICACION,\n#         PERIODO,\n#         AESPA_COD_MATERIA,\n#         Nom_materia,\n#         AESPA_ASISTENCIA\n        \n#     FROM [dbo].[vw_AESPA_ASISTENCIA_ESTUDTS_SPA]\n# \"\"\"\n# df_asistencia = pd.read_sql(query_asistencia, conn)\n\n# # Cerrar conexión \n# conn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cafcf1e2",
      "metadata": {},
      "source": [
        "#### Inicio clase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "afd785af",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\3570879745.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_inicio_clases = pd.read_sql(query_inicio_clases, conn)\n"
          ]
        }
      ],
      "source": [
        "# Crear conexión\nconn = pyodbc.connect(\n    'DRIVER={ODBC Driver 17 for SQL Server};'\n    f'SERVER={server};'\n    f'DATABASE={database};'\n    'Trusted_Connection=yes;'\n)\n\n# Consulta para obtener esas columnas\nquery_inicio_clases = \"\"\"\nSELECT \n    num_identificacion,\n    COD_PERIODO,\n    ESTADO_PAGO,\n    EstadoMoodle,\n    Ultimo_Acc_Mood,\n    Correo,\n    Horario\n    \nFROM dbo.dwh_Inicio_clases\n\"\"\"\ndf_inicio_clases = pd.read_sql(query_inicio_clases, conn)\n\n# Cerrar conexión\nconn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "579740a9",
      "metadata": {},
      "source": [
        "#### Financiacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "64bb0147",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\556862819.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_financiaciones = pd.read_sql(query_financiaciones, conn)\n"
          ]
        }
      ],
      "source": [
        "#LLAVE NUMERO_DOCUMENTO_ESTUDIANTE, PERIODO\n# Conexión\nconn = pyodbc.connect(\n    'DRIVER={ODBC Driver 17 for SQL Server};'\n    f'SERVER={server};'\n    f'DATABASE={database};'\n    'Trusted_Connection=yes;'\n)\n\n# Tabla notas\nquery_financiaciones = \"\"\"\nSELECT \n    NUMERO_DOCUMENTO_ESTUDIANTE,\n    VALOR_MATRICULA,\n    VALOR_FINANCIACION,\n    VALOR_TOTAL_FINANCIACION,\n    VALOR_CUOTA_INICIAL,\n    CUOTAS,\n    VALOR_CUOTA,\n    PERIODO\nFROM Financiera.FINANCIACIONES_CT_AYUDA\n\"\"\"\ndf_financiaciones = pd.read_sql(query_financiaciones, conn)\n\n\n# Cerrar conexión \nconn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "969f9859",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\2794303963.py:17: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_financiaciones2 = pd.read_sql(query_financiaciones2, conn)\n"
          ]
        }
      ],
      "source": [
        "\n# Conexión\nconn = pyodbc.connect(\n    'DRIVER={ODBC Driver 17 for SQL Server};'\n    f'SERVER={server};'\n    f'DATABASE={database};'\n    'Trusted_Connection=yes;'\n)\n\n# Tabla notas\nquery_financiaciones2 = \"\"\"\nSELECT \n    IDENTIFICACION,\n    PERIODO,\n    VALOR_FINANCIACION\nFROM Financiera.CTAYUDA\n\"\"\"\ndf_financiaciones2 = pd.read_sql(query_financiaciones2, conn)\n\n\n# Cerrar conexión \nconn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6dbc75e",
      "metadata": {},
      "source": [
        "### Financiera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5c3dcc38",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\992456918.py:15: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_financiera = pd.read_sql(query_financiera, conn)\n"
          ]
        }
      ],
      "source": [
        "#LLAVE NUMERO_DOCUMENTO_ESTUDIANTE, PERIODO\n# Conexión\nconn = pyodbc.connect(\n    'DRIVER={ODBC Driver 17 for SQL Server};'\n    f'SERVER={server};'\n    f'DATABASE={database};'\n    'Trusted_Connection=yes;'\n)\n\n# Tabla notas\nquery_financiera = \"\"\"\nSELECT *\nFROM Financiera.Recibos_Caja_Medios_Pago\n\"\"\"\ndf_financiera = pd.read_sql(query_financiera, conn)\n\n\n# Cerrar conexión \nconn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd2c8e8f",
      "metadata": {},
      "source": [
        "#### Información inducción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10701c58",
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_induccion = pd.read_excel(\"C:/Users/maria_castrob/OneDrive - Corporación Unificada Nacional de Educación Superior - CUN/Permanencia/ASISTENCIA INDUCCIONES.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec4539c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_induccion = df_induccion.rename(columns={\n#     'Número de documento de identidad:': \"Numero_documento\"\n# })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4fc726",
      "metadata": {},
      "source": [
        "#### Tickets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4dedd841",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39324\\68571508.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df_tickets = pd.read_sql(query_tickets, conn)\n"
          ]
        }
      ],
      "source": [
        "#LLAVE NUMERO_DOCUMENTO_ESTUDIANTE, PERIODO\n# Conexión\nconn = pyodbc.connect(\n    'DRIVER={ODBC Driver 17 for SQL Server};'\n    f'SERVER={server};'\n    f'DATABASE={database};'\n    'Trusted_Connection=yes;'\n)\n\n# Tabla notas\nquery_tickets = \"\"\"\nSELECT \n    NumeroDocumento,\n    Periodo,\n    COUNT(*) AS Total_Tickets\nFROM [ZOHO].[dbo].[VW_Tickets]\nGROUP BY NumeroDocumento, Periodo\n\"\"\"\ndf_tickets = pd.read_sql(query_tickets, conn)\n\n\n# Cerrar conexión \nconn.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94d5bbc5",
      "metadata": {},
      "source": [
        "#### Cruzar la base, con las notas del ultimo periodo del estudiante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f2c24f4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final_notas = pd.merge(\n    df_inicial,\n    df_notas_total,\n    left_on=['Id_Alumn_Programa', 'Periodo'],\n    right_on=['ID_ALUM_PROGRAMA', 'COD_PERIODO'],\n    how='left'\n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c4c2fd2",
      "metadata": {},
      "source": [
        "#### Cruzar base con la asistencia por materia del último periodo, agrupado por materia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0ed9db",
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_final_asistencia = pd.merge(\n#     df_final_notas,\n#     df_asistencia,\n#     left_on=['Identificacion', 'Periodo', 'COD_MATERIA'],\n#     right_on=['AESPA_IDENTIFICACION', 'PERIODO', 'AESPA_COD_MATERIA'],\n#     how='left'\n# )\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a61d16b5",
      "metadata": {},
      "source": [
        "#### Unión base con info de inicio de clase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bc3be988",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final_inicio_clase = pd.merge(\n    df_final_notas,\n    df_inicio_clases,\n    left_on=['Identificacion', 'Periodo'],\n    right_on=['num_identificacion','COD_PERIODO'],\n    how='left'\n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f976b6cb",
      "metadata": {},
      "source": [
        "#### Unión base financiación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f8c2eab7",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final_inicio_clase['Identificacion'] = df_final_inicio_clase['Identificacion'].astype(str)\ndf_financiaciones['NUMERO_DOCUMENTO_ESTUDIANTE'] = df_financiaciones['NUMERO_DOCUMENTO_ESTUDIANTE'].astype(str)\n\ndf_final_inicio_clase['Periodo'] = df_final_inicio_clase['Periodo'].astype(str)\ndf_financiaciones['PERIODO'] = df_financiaciones['PERIODO'].astype(str)\n\ndf_final_financiaciones = pd.merge(\n    df_final_inicio_clase,\n    df_financiaciones2,\n    left_on=['Identificacion', 'Periodo'],\n    right_on=['IDENTIFICACION','PERIODO'],\n    how='left'\n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "248388fa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VALOR_FINANCIACION\n",
              "852570.0     1807\n",
              "1155251.0    1202\n",
              "850729.0     1173\n",
              "1156010.0    1134\n",
              "1041485.0    1122\n",
              "             ... \n",
              "413953.0        1\n",
              "253766.0        1\n",
              "329040.0        1\n",
              "681575.0        1\n",
              "1405860.0       1\n",
              "Name: count, Length: 6144, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final_financiaciones['VALOR_FINANCIACION'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6f16d55",
      "metadata": {},
      "source": [
        "#### Unión base financiera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f508e70a",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final_financiera = pd.merge(\n    df_final_financiaciones,\n    df_financiera,\n    left_on=['Identificacion', 'Periodo'],\n    right_on=['IDENTIFICACION','PERIODO'],\n    how='left'\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5134227",
      "metadata": {},
      "source": [
        "### Unión info inducción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f7b51f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_final_induccion = pd.merge(\n#     df_final_financiera,\n#     df_induccion[[\"Numero_documento\"]].drop_duplicates(),\n#     left_on=\"Identificacion\",\n#     right_on=\"Numero_documento\",\n#     how=\"left\"\n# )\n\n# # Columna 1/0\n# df_final_induccion[\"Asistencia\"] = df_final_induccion[\"Numero_documento\"].notna().astype(int)\n\n# # Eliminar auxiliar\n# df_final_induccion = df_final_induccion.drop(columns=[\"Numero_documento\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25e8c9b4",
      "metadata": {},
      "source": [
        "#### Unión base tickets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "27e2e5e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final_final = pd.merge(\n    df_final_financiera,\n    df_tickets,\n    left_on=['Identificacion', 'Periodo'],\n    right_on=['NumeroDocumento','Periodo'],\n    how='left'\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6709cf0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "columnas_a_eliminar = [\n    'ID_ALUM_PROGRAMA',\n    'COD_PERIODO_x',\n    'PERIODO_x',\n    'AESPA_COD_MATERIA',\n    'num_identificacion',\n    'COD_PERIODO_y',\n    'NUMERO_DOCUMENTO_ESTUDIANTE',\n    'PERIODO_y',\n    'IDENTIFICACION',\n    'PERIODO',\n    'NumeroDocumento',\n    'IDENTIFICACION_x',\n    'IDENTIFICACION_y'\n]\n\ndf_final_final = df_final_final.drop(columns=columnas_a_eliminar, errors=\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07863f96",
      "metadata": {},
      "source": [
        "## Limpieza de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7d20ddf3",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Crear edad\ndf_final_final['DescRF_Fecha_Nacimiento'] = pd.to_datetime(df_final_final['DescRF_Fecha_Nacimiento'])\n\n# Función para calcular edad\ndef calcular_edad(fecha_nacimiento):\n    hoy = date.today()\n    return hoy.year - fecha_nacimiento.year - (\n        (hoy.month, hoy.day) < (fecha_nacimiento.month, fecha_nacimiento.day)\n    )\n\ndf_final_final['Edad'] = df_final_final['DescRF_Fecha_Nacimiento'].apply(lambda x: calcular_edad(x.date()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b4abf090",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Status trabajo\ndf_final_final['Trabaja'] = df_final_final['EE_EMPRESA'].apply(lambda x: 'TRABAJA' if pd.notnull(x) and str(x).strip() != '' else 'NO TRABAJA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f4626b93",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estandarizar unidad\ndef estandarizar(texto):\n    if pd.isna(texto):\n        return texto\n    texto = str(texto).upper()  \n    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('utf-8') \n    texto = ' '.join(texto.split())  \n    return texto\n\ndf_final_final['DescRF_Unidad'] = df_final_final['DescRF_Unidad'].apply(estandarizar)\ndf_final_final['DescRF_Unidad'] = df_final_final['DescRF_Unidad'].replace({\n    'ADMINISTRACION EMPRESAS AGROINDUSTRIALES': 'ADMINISTRACION DE EMPRESAS AGROINDUSTRIALES',\n    'DISENO DE MODA': 'PROFESIONAL EN DISENO DE MODAS',\n    'DISENO DE MODAS': 'PROFESIONAL EN DISENO DE MODAS',\n    'TECNOLOGIA EN GESTION DE PROCESOS AGROINSDUSTRIALES':'TECNOLOGIA EN GESTION DE PROCESOS AGROINDUSTRIALES',\n    'ADMINISTRACION DE EMPRESAS': 'PROFESIONAL EN ADMINISTRACION DE EMPRESAS',\n    'ADMINISTRACION DE EMPRESAS AGROINDUSTRIALES':'PROFESIONAL EN ADMINISTRACION DE EMPRESAS AGROINDUSTRIALES',\n    'ADMINISTRACION DE LA SEGURIDAD SOCIAL': 'PROFESIONAL EN ADMINISTRACION DE LA SEGURIDAD SOCIAL',\n    'ADMINISTRACION DE SERVICIOS DE SALUD': 'PROFESIONAL EN ADMINISTRACION DE SERVICIOS DE SALUD',\n    'ADMINISTRACION DEPORTIVA - BOGOTA': 'PROFESIONAL EN PROCESOS DE ADMINISTRACION DEPORTIVA - BOGOTA',\n    'ADMINISTRACION PUBLICA': 'PROFESIONAL EN ADMINISTRACION PUBLICA',\n    'ADMINISTRACION TURISTICA Y HOTELERA': 'PROFESIONAL EN ADMINISTRACION TURISTICA Y HOTELERA',\n    'COMUNICACION SOCIAL': 'PROFESIONAL EN COMUNICACION SOCIAL',\n    'CONTADURIA PUBLICA': 'PROFESIONAL EN CONTADURIA PUBLICA',\n    'PROFESIONAL EN CONTADURIA CONTABLE': 'PROFESIONAL EN CONTADURIA PUBLICA',\n    'DERECHO': 'PROFESIONAL EN DERECHO',\n    'DIRECCION Y PRODUCCION DE MEDIOS AUDIOVISUALES': 'PROFESIONAL EN DIRECCION Y PRODUCCION DE MEDIOS AUDIOVISUALES',\n    'DISENO GRAFICO': 'PROFESIONAL EN DISENO GRAFICO',\n    'DISENO Y PRODUCCION DE MODA': 'PROFESIONAL EN DISENO Y PRODUCCION DE MODA',\n    'INGENIERIAS DE SISTEMAS': 'PROFESIONAL EN INGENIERIA DE SISTEMAS',\n    'INGENIERIA DE SISTEMAS': 'PROFESIONAL EN INGENIERIA DE SISTEMAS',\n    'INGENIERIA DE ELECTRONICA': 'PROFESIONAL EN INGENIERIA ELECTRONICA',\n    'INGENIERIA ELECTRONICA': 'PROFESIONAL EN INGENIERIA ELECTRONICA',\n    'INGENIERIA DE INDUSTRIAL': 'PROFESIONAL EN INGENIERIA INDUSTRIAL',\n    'NEGOCIOS INTERNACIONALES': 'PROFESIONAL EN NEGOCIOS INTERNACIONALES',\n    'TECNICA PROFESIONAL EN SOPORTE DE SISTEMAS EN INFORMATICA': 'TECNICA PROFESIONAL EN SOPORTE DE SISTEMAS E INFORMATICA',\n    'PROFESIONAL EN COMUNICACION SOCIAL - PERIODISMO': 'PROFESIONAL EN COMUNICACION SOCIAL',\n    'TECNICA PROFESIONAL EN CONTABILIDAD Y FINANZAS': 'TECNICA PROFESIONAL EN CONTABILIDAD',\n    'TECNICA PROFESIONAL EN DISENO DE MODA Y PATRONAJE': 'TECNICA PROFESIONAL EN DISENO DE VESTUARIO Y PATRONAJE',\n    'TECNICA PROFESIONAL EN OPERACION DE PROCESOS DE PRODUCCION GRAFICA- CHILLERSITARIO': 'TECNICA PROFESIONAL EN OPERACION DE PROCESOS DE PRODUCCION GRAFICA',\n    'TECNOLOGIA EN DESARROLLO DE SOFTWARE Y REDES': 'TECNOLOGIA EN DESARROLLO DE SOFTWARE',\n    'TECNOLOGIA EN GESTION CONTABLE FINANCIERA': 'TECNOLOGIA EN GESTION CONTABLE Y FINANCIERA',\n    'TECNICO PROFESIONAL EN PRODUCCION DE CONTENIDOS INFORMATIVOS': 'TECNICA PROFESIONAL EN PRODUCCION DE CONTENIDOS INFORMATIVOS',\n    'TECNICO PROFESIONAL EN PROCESOS CONTABLES': 'TECNICA PROFESIONAL EN PROCESOS CONTABLES',\n    'TECNICO PROFESIONAL EN PROCESOS ADMINISTRATIVOS': 'TECNICA PROFESIONAL EN PROCESOS ADMINISTRATIVOS',\n    'TECNICO PROFESIONAL EN PERIODISMO INFORMATIVO': 'TECNICA PROFESIONAL EN PERIODISMO INFORMATIVO',\n    'TECNICO PROFESIONAL EN DISENO DIGITAL': 'TECNICA PROFESIONAL EN DISENO DIGITAL',\n    'ADMINISTRACION DE EMPRESAS AGROINDUSTRIALES': 'PROFESIONAL EN ADMINISTRACION DE EMPRESAS AGROINDUSTRIALES',\n    'CONTADURIA PUBLICA - VIRTUAL': 'PROFESIONAL EN CONTADURIA PUBLICA - VIRTUAL',\n    'INGENIERIA DE SISTEMAS-VIRTUAL':'PROFESIONAL EN INGENIERIA DE SISTEMAS-VIRTUAL',\n    'INGENIERIA ELECTRONICA': 'PROFESIONAL EN INGENIERIA ELECTRONICA',\n    'INGENIERIA INDUSTRIAL': 'PROFESIONAL EN INGENIERIA INDUSTRIAL',\n    'PUBLICIDAD Y MERCADEO': 'PROFESIONAL EN PUBLICIDAD Y MERCADEO'\n})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "42a39233",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estandarizar programa\ndef estandarizar(texto):\n    if pd.isna(texto):\n        return texto\n    texto = str(texto).upper()  \n    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('utf-8') \n    texto = ' '.join(texto.split())  \n    return texto\n\ndf_final_final['DescRF_Programa'] = df_final_final['DescRF_Programa'].apply(estandarizar)\ndf_final_final['DescRF_Programa'] = df_final_final['DescRF_Programa'].replace({\n    'COMUNICACION SOCIAL Y PERIODISMO': 'COMUNICACION SOCIAL',\n    'ADMINISTRACION EN SERVICIOS DE SALUD': 'ADMINISRACION DE SERVICIOS DE SALUD'\n})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "3599f63b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estandarizar regional\ndef estandarizar(texto):\n    if pd.isna(texto):\n        return texto\n    texto = str(texto).upper() \n    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('utf-8')  \n    texto = ' '.join(texto.split())  \n    return texto\n\ndf_final_final['EE_DEPARTAMENTO_REGIONAL'] = df_final_final['EE_DEPARTAMENTO_REGIONAL'].apply(estandarizar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8e3a9fea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estandarizar discapacidad\ndef estandarizar(texto):\n    if pd.isna(texto):\n        return texto\n    texto = str(texto).upper() \n    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('utf-8')  \n    texto = ' '.join(texto.split()) \n    return texto\n\ndf_final_final['EE_OTRA_DISCAPACIDAD'] = df_final_final['EE_OTRA_DISCAPACIDAD'].apply(estandarizar)\ndf_final_final['EE_OTRA_DISCAPACIDAD'] = df_final_final['EE_OTRA_DISCAPACIDAD'].replace({\n    'NINGUNO': 'NINGUNA',\n    'DISCAPACIDAD FISICA': 'FISICA'\n})    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0ec1cc74",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clasificar las deserciones\ndef target(x): \n    if x == 'Desercion CUN':\n        return 1 \n    else: \n        return 0 \ndf_final_final['DescRF_Status'] = df_final_final.apply(lambda x: target(x.DescRF_Status),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3d2077e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estandarizar estados\ndef rec_tipo_estado(x): \n    if x == 'Nuevo - Homologado':\n        return 'NUEVO'\n    else: \n        return x \ndf_final_final['DescRF_Tipo_estado_alumno'] = df_final_final.apply(lambda x: rec_tipo_estado(x.DescRF_Tipo_estado_alumno),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2b5b927f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estandarizar modalidad\ndef rec_modalidad(x):\n    if x == 'Presencial Fin De Semana':\n        return 'Presencial'\n    elif x == 'No Presencial':\n        return 'Virtual'\n    else:\n        return x \ndf_final_final['DescRF_Modalidad'] = df_final_final.apply(lambda x: rec_modalidad(x.DescRF_Modalidad),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2b48c3b5",
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "'a' cannot be empty unless no samples are taken",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m     probs = no_nulos.value_counts(normalize=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m     n_missing = df_desertores_final[x].isna().sum()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     imputados = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     df_desertores_final.loc[df_desertores_final[x].isna(), x] = imputados\n\u001b[32m     10\u001b[39m df_final_final.EE_ESTRATO_ACTUALIZADO.value_counts(dropna=\u001b[38;5;28;01mFalse\u001b[39;00m,normalize=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/mtrand.pyx:970\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.choice\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m: 'a' cannot be empty unless no samples are taken"
          ]
        }
      ],
      "source": [
        "# Manejo estrato\ncol = ['EE_ESTRATO_ACTUALIZADO']\ndf_desertores_final = df_final_final\nfor x in col:\n    no_nulos = df_desertores_final[x].dropna()\n    probs = no_nulos.value_counts(normalize=True)\n    n_missing = df_desertores_final[x].isna().sum()\n    imputados = np.random.choice(probs.index, size=n_missing, p=probs.values)\n    df_desertores_final.loc[df_desertores_final[x].isna(), x] = imputados\ndf_final_final.EE_ESTRATO_ACTUALIZADO.value_counts(dropna=False,normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "177ee4e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estandarizar estado pago\ndef rec_estado_pago(x):\n    if x == 'PAGO':\n        return x \n    else:\n        return 'NO'\ndf_final_final['ESTADO_PAGO'] = df_final_final.apply(lambda x: rec_estado_pago(x.ESTADO_PAGO),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6a1b383d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manejo DescRF_Acceso_Moodle a fecha \ndf_final_final['Ultimo_Acc_Mood'] = pd.to_datetime(df_final_final['Ultimo_Acc_Mood'],errors='coerce')\n\nfecha_actual = pd.to_datetime(datetime.now().date())\ndf_final_final['diferencia_dias_moodle_u'] = (fecha_actual - df_final_final['Ultimo_Acc_Mood']).dt.days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "5e4642a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Estado Moodle\n\ndf_final_final['NA_Calificaciones'] = df_final_final['NOT_PERIODO'].isna()\n#df_final_final['EstadoMoodle'] = df_final_final.apply(lambda x: rec_estado(x.NA_Calificaciones,x.EstadoMoodle),axis=1)\n\ndef rec_estado(x,y):\n    if x == False:\n        return 'ACTIVO'\n    else:\n        return y\ndf_final_final['EstadoMoodle'] = df_final_final.apply(lambda x: rec_estado(x.NA_Calificaciones,x.EstadoMoodle),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "dd2daa47",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Horarios\ndef rec_horario(x,y):\n    if x == False:\n        return 'SI'\n    else:\n        return 'NO'\ndf_final_final['Horario'] = df_final_final.apply(lambda x: rec_horario(x.NA_Calificaciones,x.Horario),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "de7f0aae",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Correo \ndef rec_correo(x):\n    if x == 'SI':\n        return x\n    else:\n        return 'NO'\ndf_final_final['Correo'] = df_final_final.apply(lambda x: rec_correo(x.Correo),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "58d031e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Recibo de Caja \ndef rec_recibo_caja(x,y):\n    if x == True:\n        return 0\n    else:\n        return y   \ndf_final_final['NA_RECIBOS'] = df_final_final['RECIBOS_CAJA'].isna()\ndf_final_final['RECIBOS_CAJA'] = df_final_final.apply(lambda x: rec_recibo_caja(x.NA_RECIBOS,x.RECIBOS_CAJA),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "86a8b58a",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Icetex \ndf_final_final['NA_ICETEX'] = df_final_final['ICETEX'].isna()\ndf_final_final['ICETEX'] = df_final_final.apply(lambda x: rec_recibo_caja(x.NA_ICETEX,x.ICETEX),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7654ceb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Fincomercio \ndf_final_final['NA_FINCOMERCIO'] = df_final_final['FINCOMERCIO'].isna()\ndf_final_final['FINCOMERCIO'] = df_final_final.apply(lambda x: rec_recibo_caja(x.NA_FINCOMERCIO,x.FINCOMERCIO),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "26bbb28b",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Credity \ndf_final_final['NA_CREDITY'] = df_final_final['CREDITY'].isna()\ndf_final_final['CREDITY'] = df_final_final.apply(lambda x: rec_recibo_caja(x.NA_CREDITY,x.CREDITY),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "50119fab",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Total_Tickets\ndf_final_final['NA_Total_Tickets'] = df_final_final['Total_Tickets'].isna()\ndf_final_final['Total_Tickets'] = df_final_final.apply(lambda x: rec_recibo_caja(x.NA_Total_Tickets,x.Total_Tickets),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "960547b7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Identificacion', 'Periodo', 'DescRF_Status',\n",
              "       'DescRF_Tipo_estado_alumno', 'DescRF_Modalidad', 'DescRF_Semestre_SINU',\n",
              "       'DescRF_ciclo', 'DescRF_SEMESTRE_MEN', 'DescRF_Genero', 'DescRF_Unidad',\n",
              "       'DescRF_Jornada', 'DescRF_Periodo_Ult_Pago', 'DescRF_Sede',\n",
              "       'DescRF_Regional', 'DescRF_Programa', 'DescRF_Acceso_Moodle',\n",
              "       'DescRF_tipo_estudio', 'Id_Alumn_Programa', 'DescRF_Tipo_Alumno',\n",
              "       'DescRF_Nuevo', 'DescRF_orden', 'DescRF_Fecha_Liquidacion',\n",
              "       'DescRF_Fecha_Nacimiento', 'DescRF_ultimo_curso',\n",
              "       'DescAM_MATERIAS_INSCRITAS', 'DescAM_MATERIAS_APROBADAS',\n",
              "       'DescAM_Porcentaje_aprobacion', 'EEpromedio', 'EE_UNIDADNEGOCIO',\n",
              "       'EE_DEPARTAMENTO_REGIONAL', 'EE_OTRA_DISCAPACIDAD', 'EE_SISTEMA_SALUD',\n",
              "       'EE_ESTRATO_ACTUALIZADO', 'EE_EMPRESA', 'COD_MATERIA', 'DEF_HISTORIA',\n",
              "       'NOT_PERIODO', 'ESTADO_PAGO', 'EstadoMoodle', 'Ultimo_Acc_Mood',\n",
              "       'Correo', 'Horario', 'VALOR_FINANCIACION', 'RECIBOS_CAJA', 'ICETEX',\n",
              "       'FINCOMERCIO', 'CREDITY', 'JAC', 'CONVENIOV', 'Total_Tickets', 'Edad',\n",
              "       'Trabaja', 'diferencia_dias_moodle_u', 'NA_Calificaciones',\n",
              "       'NA_RECIBOS', 'NA_ICETEX', 'NA_FINCOMERCIO', 'NA_CREDITY',\n",
              "       'NA_Total_Tickets'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final_final.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8e7a7864",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Tabla COE.df_final_GRU creada exitosamente en CUN_REPOSITORIO.\n",
            "📊 Registros insertados: 1750326\n"
          ]
        }
      ],
      "source": [
        "import os\n# -*- coding: utf-8 -*-\nimport pandas as pd\nfrom sqlalchemy import create_engine, text\n\n# ===============================================\n# CONFIGURACIÓN DE CONEXIÓN\n# ===============================================\n# Ajusta tus credenciales y servidor\nusuario = os.environ.get(\"SQL_USER\",\"\")\nclave = os.environ.get(\"SQL_PASSWORD\",\"\")#$&/$*\"    # cuidado con caracteres especiales\nservidor = os.environ.get(\"SQL_SERVER\",\"\")\nbase_datos = os.environ.get(\"SQL_DB\",\"\")\nschema = os.environ.get(\"SQL_SCHEMA\",\"COE\")\ntabla = \"df_final_GRU\"\n\n# Crear conexión con SQL Server (usa pyodbc)\nconnection_string = (\n    f\"mssql+pyodbc://{usuario}:{clave}@{servidor}/{base_datos}?driver=ODBC+Driver+17+for+SQL+Server\"\n)\nengine = create_engine(connection_string, fast_executemany=True)\n\n# ===============================================\n# CREAR TABLA (REEMPLAZAR SI YA EXISTE)\n# ===============================================\nwith engine.begin() as conn:\n    # Si la tabla ya existe, se elimina primero (opcional)\n    conn.execute(text(f\"IF OBJECT_ID('{schema}.{tabla}', 'U') IS NOT NULL DROP TABLE {schema}.{tabla};\"))\n    \n    # Crear tabla desde el DataFrame\n    df_final_final.to_sql(tabla, con=conn, schema=schema, index=False, if_exists='replace')\n    print(f\"✅ Tabla {schema}.{tabla} creada exitosamente en {base_datos}.\")\n\n# ===============================================\n# VERIFICAR REGISTROS INSERTADOS\n# ===============================================\nwith engine.connect() as conn:\n    result = conn.execute(text(f\"SELECT COUNT(*) FROM {schema}.{tabla}\"))\n    total = result.scalar()\n    print(f\"📊 Registros insertados: {total}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a4088e7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Identificacion</th>\n",
              "      <th>Periodo</th>\n",
              "      <th>DescRF_Status</th>\n",
              "      <th>DescRF_Tipo_estado_alumno</th>\n",
              "      <th>DescRF_Modalidad</th>\n",
              "      <th>DescRF_Semestre_SINU</th>\n",
              "      <th>DescRF_ciclo</th>\n",
              "      <th>DescRF_SEMESTRE_MEN</th>\n",
              "      <th>DescRF_Genero</th>\n",
              "      <th>DescRF_Unidad</th>\n",
              "      <th>...</th>\n",
              "      <th>Total_Tickets</th>\n",
              "      <th>Edad</th>\n",
              "      <th>Trabaja</th>\n",
              "      <th>diferencia_dias_moodle_u</th>\n",
              "      <th>NA_Calificaciones</th>\n",
              "      <th>NA_RECIBOS</th>\n",
              "      <th>NA_ICETEX</th>\n",
              "      <th>NA_FINCOMERCIO</th>\n",
              "      <th>NA_CREDITY</th>\n",
              "      <th>NA_Total_Tickets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00010105021</td>\n",
              "      <td>2017B</td>\n",
              "      <td>1</td>\n",
              "      <td>NUEVO</td>\n",
              "      <td>Presencial</td>\n",
              "      <td>1</td>\n",
              "      <td>TECNICO</td>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>TECNICA PROFESIONAL EN LOGISTICA DE COMERCIO E...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25</td>\n",
              "      <td>NO TRABAJA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00010105021</td>\n",
              "      <td>2017B</td>\n",
              "      <td>1</td>\n",
              "      <td>NUEVO</td>\n",
              "      <td>Presencial</td>\n",
              "      <td>1</td>\n",
              "      <td>TECNICO</td>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>TECNICA PROFESIONAL EN LOGISTICA DE COMERCIO E...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25</td>\n",
              "      <td>NO TRABAJA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00010105021</td>\n",
              "      <td>2017B</td>\n",
              "      <td>1</td>\n",
              "      <td>NUEVO</td>\n",
              "      <td>Presencial</td>\n",
              "      <td>1</td>\n",
              "      <td>TECNICO</td>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>TECNICA PROFESIONAL EN LOGISTICA DE COMERCIO E...</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25</td>\n",
              "      <td>NO TRABAJA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 59 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  Identificacion Periodo  DescRF_Status DescRF_Tipo_estado_alumno  \\\n",
              "0    00010105021   2017B              1                     NUEVO   \n",
              "1    00010105021   2017B              1                     NUEVO   \n",
              "2    00010105021   2017B              1                     NUEVO   \n",
              "\n",
              "  DescRF_Modalidad  DescRF_Semestre_SINU DescRF_ciclo DescRF_SEMESTRE_MEN  \\\n",
              "0       Presencial                     1      TECNICO                   2   \n",
              "1       Presencial                     1      TECNICO                   2   \n",
              "2       Presencial                     1      TECNICO                   2   \n",
              "\n",
              "  DescRF_Genero                                      DescRF_Unidad  ...  \\\n",
              "0             M  TECNICA PROFESIONAL EN LOGISTICA DE COMERCIO E...  ...   \n",
              "1             M  TECNICA PROFESIONAL EN LOGISTICA DE COMERCIO E...  ...   \n",
              "2             M  TECNICA PROFESIONAL EN LOGISTICA DE COMERCIO E...  ...   \n",
              "\n",
              "  Total_Tickets Edad     Trabaja diferencia_dias_moodle_u NA_Calificaciones  \\\n",
              "0           0.0   25  NO TRABAJA                      NaN             False   \n",
              "1           0.0   25  NO TRABAJA                      NaN             False   \n",
              "2           0.0   25  NO TRABAJA                      NaN             False   \n",
              "\n",
              "  NA_RECIBOS NA_ICETEX  NA_FINCOMERCIO NA_CREDITY NA_Total_Tickets  \n",
              "0       True      True            True       True             True  \n",
              "1       True      True            True       True             True  \n",
              "2       True      True            True       True             True  \n",
              "\n",
              "[3 rows x 59 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final_final.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cee8a76",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final_final.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e59f824b",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final_final.to_csv(\"base_fin_permanencia.csv.gz\", index=False, compression='gzip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d47b300e",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_final_final = pd.read_csv(\n    \"C:/Users/maria_castrob/OneDrive - Corporación Unificada Nacional de Educación Superior - CUN/base_fin_permanencia.csv.gz\",\n    compression=\"gzip\",\n    sep=\",\",  \n    engine=\"python\"\n)\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13629eb5",
      "metadata": {},
      "source": [
        "### Creación base semana inicial"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68486aa7",
      "metadata": {},
      "source": [
        "### Variables para modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78246ffc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lista de variables seleccionadas\ndf_modelo = ['Identificacion','DescRF_Unidad','DescRF_Status',\n    'DescRF_Modalidad', 'DescRF_ciclo', 'DescRF_SEMESTRE_MEN', 'DescRF_Genero',\n    'DescRF_Unidad', 'DescRF_Jornada', 'DescRF_Sede', 'DescRF_Regional',\n    'DescRF_Programa', 'DescRF_Acceso_Moodle', 'DescRF_tipo_estudio',\n    'DescRF_Tipo_Alumno', 'DescRF_Nuevo', 'DescRF_orden',\n    'DescAM_MATERIAS_INSCRITAS', 'DescAM_MATERIAS_APROBADAS',\n    'DescAM_Porcentaje_aprobacion', 'EEpromedio', 'EE_ESTRATO_ACTUALIZADO',\n    'COD_MATERIA', 'DEF_HISTORIA', 'NOT_PERIODO', 'ESTADO_PAGO', 'EstadoMoodle',\n    'Correo', 'Horario', 'RECIBOS_CAJA', 'ICETEX',\n    'FINCOMERCIO', 'CREDITY','Total_Tickets',\n    'Edad', 'Trabaja'\n]\n\n# Crear la base del modelo a partir de df_final_final\nbase_modelo = df_final_final[df_modelo].copy()\n\n# Verificar\nprint(base_modelo.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40c57e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "#base_modelo.to_csv(\"base_modelo_permanencia.csv.gz\", index=False, compression='gzip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22bde66e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#base_modelo.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5972b8ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "#base_modelo.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c8d0be5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas duplicadas: Index(['DescRF_Unidad'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Antes de todo\ndups = base_modelo.columns[base_modelo.columns.duplicated()]\nprint(\"Columnas duplicadas:\", dups)\n\n# Nos quedamos solo con la primera aparición de cada nombre de columna\nbase_modelo = base_modelo.loc[:, ~base_modelo.columns.duplicated()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb29df37",
      "metadata": {},
      "outputs": [],
      "source": [
        "categoricas = base_modelo[variables_predictoras].select_dtypes(include=['object', 'category']).columns\nbase_modelo_encoded = pd.get_dummies(base_modelo, columns=categoricas, dummy_na=True)\n\n# Por si acaso, también puedes asegurar que en el codificado no queden duplicadas:\nbase_modelo_encoded = base_modelo_encoded.loc[:, ~base_modelo_encoded.columns.duplicated()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "044e4ccb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Columnas con alta cardinalidad identificadas como problemáticas:\ncolumnas_alta_cardinalidad = [\n    'DescRF_Unidad', \n    'DescRF_Programa', \n    'COD_MATERIA',\n    'DescRF_Sede', \n    'DescRF_Regional'\n]\n\n# Definir un umbral de frecuencia. \n# Si un valor aparece menos de este número de veces, será agrupado como 'OTRO'.\n# Para un dataset de 1.75 millones de filas, un umbral de 1000 a 5000 es un buen punto de partida.\nUMBRAL_FRECUENCIA = 1000 \n\nprint(f\"Reduciendo cardinalidad para: {columnas_alta_cardinalidad} con un umbral de {UMBRAL_FRECUENCIA} apariciones.\")\n\nfor col in columnas_alta_cardinalidad:\n    # 1. Calcular la frecuencia de cada valor\n    frecuencias = base_modelo[col].value_counts()\n    \n    # 2. Identificar los valores raros (frecuencia menor al umbral)\n    valores_raros = frecuencias[frecuencias < UMBRAL_FRECUENCIA].index\n    \n    # 3. Reemplazar los valores raros por 'OTRO'\n    if len(valores_raros) > 0:\n        base_modelo[col] = base_modelo[col].replace(valores_raros, 'OTRO')\n        print(f\"  Columna '{col}': {len(valores_raros)} categorías agrupadas en 'OTRO'. Nueva cardinalidad: {base_modelo[col].nunique()}\")\n    else:\n        print(f\"  Columna '{col}': No se encontraron categorías raras.\")\n\n# Convertir las columnas categóricas a tipo 'category' para optimizar la memoria antes del OHE\n# Esto ayuda a que el siguiente paso (get_dummies) sea más eficiente\ncategoricas_optimizables = base_modelo.select_dtypes(include=['object']).columns\nfor col in categoricas_optimizables:\n    base_modelo[col] = base_modelo[col].astype('category')\n\nprint(\"Proceso de reducción de cardinalidad y optimización de memoria completado.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3742ca93",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Target definido\ntarget = 'DescRF_Status'\n# Y que el identificador del estudiante esté claro\nid_estudiante = 'Identificacion'\n\n# 2. Definir las variables y en qué semana aparecen\n# (AJUSTA ESTAS LISTAS SEGÚN TU CONOCIMIENTO DEL PROCESO)\nsemanas_totales = 16\n\nvars_sem_1 = [\n    'DescRF_Modalidad', 'DescRF_ciclo', 'DescRF_SEMESTRE_MEN', 'DescRF_Genero',\n    'DescRF_Unidad', 'DescRF_Jornada', 'DescRF_Sede', 'DescRF_Regional',\n    'DescRF_Programa', 'DescRF_tipo_estudio', 'DescRF_Tipo_Alumno',\n    'DescRF_Nuevo', 'EE_ESTRATO_ACTUALIZADO', 'ESTADO_PAGO',\n    'Correo', 'Horario', 'Edad', 'Trabaja'\n]\nvars_sem_3 = vars_sem_1 + ['DescRF_Acceso_Moodle', 'Total_Tickets']\nvars_sem_8 = vars_sem_3 + [  'DescAM_MATERIAS_INSCRITAS']\nvars_sem_12 = vars_sem_8 + [\n    'RECIBOS_CAJA', 'ICETEX', 'FINCOMERCIO', 'CREDITY',\n    'DescAM_MATERIAS_APROBADAS', 'DescAM_Porcentaje_aprobacion', 'EEpromedio',\n    'DEF_HISTORIA', 'NOT_PERIODO'\n]\n\n# Lista con todas las variables predictoras\nvariables_predictoras = sorted(list(set(vars_sem_12)))\n\n# 3. One-Hot Encoding para variables categóricas\n# El modelo GRU necesita solo números.\ncategoricas = base_modelo[variables_predictoras].select_dtypes(include=['object', 'category']).columns\nbase_modelo_encoded = pd.get_dummies(base_modelo, columns=categoricas, dummy_na=True)\n\n# Actualizar la lista de variables predictoras con las nuevas columnas dummies\nvariables_predictoras_encoded = [\n    col for col in base_modelo_encoded.columns if any(var in col for var in variables_predictoras)\n]\n\n\n# 4. Crear el DataFrame secuencial\nlista_dfs_semanales = []\n\nfor semana in range(1, semanas_totales + 1):\n    df_semana = base_modelo_encoded[[id_estudiante, target]].copy()\n    df_semana['semana'] = semana\n\n    # Determinar qué variables están disponibles en esta semana\n    vars_disponibles = []\n    if semana >= 1:\n        vars_disponibles.extend(vars_sem_1)\n    if semana >= 3:\n        vars_disponibles.extend(vars_sem_3)\n    if semana >= 8:\n        vars_disponibles.extend(vars_sem_8)\n    if semana >= 12:\n        vars_disponibles.extend(vars_sem_12)\n    \n    # Obtener las columnas dummy correspondientes a las vars disponibles\n    cols_disponibles_encoded = [\n        col for col in variables_predictoras_encoded if any(var in col for var in set(vars_disponibles))\n    ]\n    \n    # Añadir solo las columnas disponibles para esta semana\n    for col in variables_predictoras_encoded:\n        if col in cols_disponibles_encoded:\n            df_semana[col] = base_modelo_encoded[col]\n        else:\n            # np.nan es el valor que la capa Masking de Keras ignorará\n            df_semana[col] = np.nan\n\n    lista_dfs_semanales.append(df_semana)\n\n# Unir todos los dataframes semanales en uno solo\ndf_secuencial = pd.concat(lista_dfs_semanales, ignore_index=True)\n\n# 5. Guardar el archivo final listo para el modelo GRU\ndf_secuencial.to_csv(\"datos_secuenciales_para_gru.csv.gz\", index=False, compression='gzip')\n\nprint(\"¡Archivo secuencial creado con éxito!\")\nprint(df_secuencial.shape)\nprint(df_secuencial.head())\nprint(df_secuencial.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42b703d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np # <-- ¡Añadir esta línea si no está ya!\n\n# ... (El código anterior: definiciones de target, id_estudiante, semanas, y vars_sem_X)\n\n# 3. One-Hot Encoding para variables categóricas\n# El modelo GRU necesita solo números.\ncategoricas = base_modelo[variables_predictoras].select_dtypes(include=['object', 'category']).columns\nbase_modelo_encoded = pd.get_dummies(base_modelo, columns=categoricas, dummy_na=True)\n\n# *** CORRECCIÓN APLICADA AQUÍ ***\n# Sanitizar nombres de columnas: Reemplazar espacios y caracteres especiales en los nombres de columna\n# para evitar el error de slicing con nombres largos.\nbase_modelo_encoded.columns = base_modelo_encoded.columns.str.replace(' ', '_', regex=False)\nbase_modelo_encoded.columns = base_modelo_encoded.columns.str.replace('[^A-Za-z0-9_]+', '', regex=True)\n\n# Actualizar la lista de variables predictoras con las nuevas columnas dummies\n# También se debe sanitizar la lista 'variables_predictoras' para que la condición 'var in col' funcione\nvariables_predictoras_sanitized = [var.replace(' ', '_').replace('[^A-Za-z0-9_]+', '', regex=True) \n                                   for var in variables_predictoras]\n\nvariables_predictoras_encoded = [\n    col for col in base_modelo_encoded.columns \n    if any(var in col for var in variables_predictoras_sanitized)\n]\n# ***********************************\n\n# 4. Crear el DataFrame secuencial\nlista_dfs_semanales = []\nfor semana in range(1, semanas_totales + 1):\n    df_semana = base_modelo_encoded[[id_estudiante, target]].copy()\n    df_semana['semana'] = semana\n\n    # Determinar qué variables están disponibles en esta semana\n    vars_disponibles = []\n    if semana >= 1:\n        # Usar la lista no sanitizada para facilitar la definición inicial\n        vars_disponibles.extend(vars_sem_1)\n    if semana >= 3:\n        # Aquí se añaden las nuevas variables que están solo en vars_sem_3\n        vars_disponibles.extend([var for var in vars_sem_3 if var not in vars_sem_1])\n    if semana >= 8:\n        # Aquí se añaden las nuevas variables que están solo en vars_sem_8\n        vars_disponibles.extend([var for var in vars_sem_8 if var not in vars_sem_3])\n    if semana >= 12:\n        # Aquí se añaden las nuevas variables que están solo en vars_sem_12\n        vars_disponibles.extend([var for var in vars_sem_12 if var not in vars_sem_8])\n    \n    # Sanitizar las variables disponibles para que coincidan con los nombres de columna en base_modelo_encoded\n    vars_disponibles_sanitized = [var.replace(' ', '_').replace('[^A-Za-z0-9_]+', '', regex=True) \n                                  for var in set(vars_disponibles)]\n                                  \n    # Obtener las columnas dummy correspondientes a las vars disponibles\n    cols_disponibles_encoded = [\n        col for col in variables_predictoras_encoded\n        if any(var in col for var in vars_disponibles_sanitized)\n    ]\n\n    # Añadir solo las columnas disponibles para esta semana\n    for col in variables_predictoras_encoded:\n        if col in cols_disponibles_encoded:\n            # Línea que fallaba: ahora 'col' es un nombre sanitizado y funciona\n            df_semana[col] = base_modelo_encoded[col]\n        else:\n            # np.nan es el valor que la capa Masking de Keras ignorará\n            df_semana[col] = np.nan\n\n    lista_dfs_semanales.append(df_semana)\n\n# Unir todos los dataframes semanales en uno solo\ndf_secuencial = pd.concat(lista_dfs_semanales, ignore_index=True)\n\n# 5. Guardar el archivo final listo para el modelo GRU\ndf_secuencial.to_csv(\"datos_secuenciales_para_gru.csv.gz\", index=False, compression='gzip')\nprint(\"¡Archivo secuencial creado con éxito!\")\nprint(df_secuencial.shape)\nprint(df_secuencial.head())\nprint(df_secuencial.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8da1d1c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "base_modelo.to_csv(\"base_modelo_permanencia.csv\", index=False, compression='gzip')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}