{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f457b626",
      "metadata": {},
      "outputs": [],
      "source": [
        "####################################################################\n#################### CODIGO CORREGIDO ##############################\n####################################################################\n\nimport os\nimport urllib.parse\n\nimport pandas as pd\nfrom sqlalchemy import create_engine, text\n\n# ==========================\n# 1. CONFIGURACIÓN BÁSICA\n# ==========================\n\n# Ruta del archivo de entrada (tu Excel)\nruta_entrada = os.environ.get(\"INPUT_EXCEL\", r\"data/subida.xlsx\")\n\n# Parámetros de conexión a SQL Server\nserver = os.environ.get(\"SQL_SERVER\", \"localhost\")                # ej: \"10.0.0.1\" o \"MI_SERVER\\SQL2019\"\ndatabase = os.environ.get(\"SQL_DB\", \"\")           # ej: \"CUN_REPOSITORIO\"\ndriver = os.environ.get(\"SQL_DRIVER\", \"ODBC Driver 17 for SQL Server\")  # Ajusta si usas otro\n\n# Tabla destino (donde deben quedar los datos al final)\nschema_destino = \"COE\"\ntabla_destino = \"CLTIENE_LLAMADAS\"\n\n# Nombre de la tabla temporal (física)\ntabla_temporal = f\"{tabla_destino}_TEMP_CARGA\"\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9359ac74",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registros cargados desde Excel: (4859, 37)\n"
          ]
        }
      ],
      "source": [
        "\n# =======================================================\n# 2. CARGAR EXCEL EN PANDAS (ORIGEN DE LOS REGISTROS)\n# =======================================================\n\nif not os.path.exists(ruta_entrada):\n    raise FileNotFoundError(f\"La ruta no existe: {ruta_entrada}\")\n\n# Aquí cargas la hoja correcta\ndf = pd.read_excel(ruta_entrada, sheet_name=\"Sheet1\")\n\nprint(\"Registros cargados desde Excel:\", df.shape)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b616cd40",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n# =======================================================\n# 3. CREAR ENGINE DE SQLALCHEMY PARA SQL SERVER\n# =======================================================\n\nparams = urllib.parse.quote_plus(\n    f\"DRIVER={{{driver}}};\"\n    f\"SERVER={server};\"\n    f\"DATABASE={database};\"\n    f\"Trusted_Connection=yes;\"  # O reemplaza por UID=...;PWD=...; si usas usuario/clave\n)\n\nengine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a7f13170",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas encontradas en tabla destino:\n",
            "                          COLUMN_NAME DATA_TYPE  CHARACTER_MAXIMUM_LENGTH  \\\n",
            "0                               Fecha  nvarchar                     255.0   \n",
            "1   Contacto (Identificacion - Nombre  nvarchar                     255.0   \n",
            "2                            Telefono     float                       NaN   \n",
            "3                              Agente  nvarchar                     255.0   \n",
            "4                              Cuenta  nvarchar                     255.0   \n",
            "5                              Modulo  nvarchar                     255.0   \n",
            "6                   Nombre del Modulo  nvarchar                     255.0   \n",
            "7                              Motivo  nvarchar                     255.0   \n",
            "8                Estado de la LLamada  nvarchar                     255.0   \n",
            "9                  Tiempo  de Llamada  nvarchar                     255.0   \n",
            "10            Tiempo  de Conversacion  nvarchar                     255.0   \n",
            "11                 Estado de Registro  nvarchar                     255.0   \n",
            "12                  Estado de Gestion  nvarchar                     255.0   \n",
            "13         Calificacion de la Llamada  nvarchar                     255.0   \n",
            "14              Direccion grabacion#1  nvarchar                     255.0   \n",
            "15              Direccion grabacion#2     float                       NaN   \n",
            "16              Direccion grabacion#3     float                       NaN   \n",
            "17              Direccion grabacion#4     float                       NaN   \n",
            "18              Direccion grabacion#5     float                       NaN   \n",
            "19              Direccion grabacion#6     float                       NaN   \n",
            "20              Direccion grabacion#7  nvarchar                     255.0   \n",
            "21                         Comentario  nvarchar                     255.0   \n",
            "22                            archivo  nvarchar                     255.0   \n",
            "23                     saludo_inicial     float                       NaN   \n",
            "24             identificacion_cliente     float                       NaN   \n",
            "25               comprension_problema     float                       NaN   \n",
            "26              ofrecimiento_solucion     float                       NaN   \n",
            "27                 manejo_inquietudes     float                       NaN   \n",
            "28                    cierre_servicio     float                       NaN   \n",
            "29                       proximo_paso     float                       NaN   \n",
            "30                           efectiva     float                       NaN   \n",
            "31                           polarity     float                       NaN   \n",
            "32                       subjectivity     float                       NaN   \n",
            "33                      clasificacion  nvarchar                     255.0   \n",
            "34                          confianza     float                       NaN   \n",
            "35                           palabras     float                       NaN   \n",
            "36                               tipo  nvarchar                     255.0   \n",
            "\n",
            "    NUMERIC_PRECISION NUMERIC_SCALE IS_NULLABLE  \n",
            "0                 NaN          None         YES  \n",
            "1                 NaN          None         YES  \n",
            "2                53.0          None         YES  \n",
            "3                 NaN          None         YES  \n",
            "4                 NaN          None         YES  \n",
            "5                 NaN          None         YES  \n",
            "6                 NaN          None         YES  \n",
            "7                 NaN          None         YES  \n",
            "8                 NaN          None         YES  \n",
            "9                 NaN          None         YES  \n",
            "10                NaN          None         YES  \n",
            "11                NaN          None         YES  \n",
            "12                NaN          None         YES  \n",
            "13                NaN          None         YES  \n",
            "14                NaN          None         YES  \n",
            "15               53.0          None         YES  \n",
            "16               53.0          None         YES  \n",
            "17               53.0          None         YES  \n",
            "18               53.0          None         YES  \n",
            "19               53.0          None         YES  \n",
            "20                NaN          None         YES  \n",
            "21                NaN          None         YES  \n",
            "22                NaN          None         YES  \n",
            "23               53.0          None         YES  \n",
            "24               53.0          None         YES  \n",
            "25               53.0          None         YES  \n",
            "26               53.0          None         YES  \n",
            "27               53.0          None         YES  \n",
            "28               53.0          None         YES  \n",
            "29               53.0          None         YES  \n",
            "30               53.0          None         YES  \n",
            "31               53.0          None         YES  \n",
            "32               53.0          None         YES  \n",
            "33                NaN          None         YES  \n",
            "34               53.0          None         YES  \n",
            "35               53.0          None         YES  \n",
            "36                NaN          None         YES  \n"
          ]
        }
      ],
      "source": [
        "# =======================================================\n# 4. LEER EL ESQUEMA DE LA TABLA DESTINO DESDE SQL\n# =======================================================\n\nquery_schema = text(\"\"\"\nSELECT \n    COLUMN_NAME,\n    DATA_TYPE,\n    CHARACTER_MAXIMUM_LENGTH,\n    NUMERIC_PRECISION,\n    NUMERIC_SCALE,\n    IS_NULLABLE\nFROM INFORMATION_SCHEMA.COLUMNS\nWHERE TABLE_SCHEMA = :schema\n  AND TABLE_NAME = :tabla\nORDER BY ORDINAL_POSITION;\n\"\"\")\n\nwith engine.connect() as conn:\n    schema_df = pd.read_sql(query_schema, conn, params={\"schema\": schema_destino, \"tabla\": tabla_destino})\n\nprint(\"Columnas encontradas en tabla destino:\")\nprint(schema_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "05b80384",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ DataFrame convertido a tipos compatibles con SQL.\n"
          ]
        }
      ],
      "source": [
        "\n\n# =======================================================\n# 5. FUNCIÓN PARA CONVERTIR TIPOS SEGÚN ESQUEMA SQL\n# =======================================================\n\ndef convertir_dataframe_a_esquema_sql(df_origen: pd.DataFrame, schema_sql: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Convierte el DataFrame de entrada a los tipos que espera SQL Server\n    según INFORMATION_SCHEMA.COLUMNS.\n    Aquí asumimos que el Excel TIENE todas las columnas de la tabla en SQL.\n    \"\"\"\n\n    # ---- 5.1 Normalizar nombres de columnas (case-insensitive) ----\n    # Mapeo: nombre_en_minuscula -> nombre_exactamente_como_en_SQL\n    mapeo_nombres = {col.lower(): col for col in schema_sql[\"COLUMN_NAME\"]}\n\n    df_renombrado = df_origen.copy()\n    df_renombrado.columns = [\n        mapeo_nombres.get(str(c).lower(), str(c))  # si coincide por lower, usamos el de SQL\n        for c in df_renombrado.columns\n    ]\n\n    cols_sql = set(schema_sql[\"COLUMN_NAME\"])\n    cols_excel = set(df_renombrado.columns)\n\n    # Columnas que SQL espera y NO están en el Excel (esto sí es error duro)\n    faltantes = cols_sql - cols_excel\n\n    # Columnas que vienen en Excel pero NO existen en la tabla destino (se pueden ignorar)\n    sobrantes = cols_excel - cols_sql\n\n    if faltantes:\n        raise ValueError(\n            f\"El Excel NO tiene estas columnas que sí existen en {schema_destino}.{tabla_destino}: \"\n            f\"{sorted(faltantes)}\"\n        )\n\n    if sobrantes:\n        print(\"⚠️ Aviso: Estas columnas vienen en el Excel pero NO existen en la tabla destino \"\n              f\"{schema_destino}.{tabla_destino} y serán ignoradas:\")\n        print(sorted(sobrantes))\n        df_renombrado = df_renombrado.drop(columns=list(sobrantes))\n\n    # A partir de aquí, df_renombrado solo tiene columnas que están en la tabla SQL\n    df_convertido = df_renombrado.copy()\n    errores = []\n\n    for _, row in schema_sql.iterrows():\n        col = row[\"COLUMN_NAME\"]\n        tipo = row[\"DATA_TYPE\"]\n        max_len = row[\"CHARACTER_MAXIMUM_LENGTH\"]\n        is_nullable = row[\"IS_NULLABLE\"]\n\n        # Ya garantizamos que la columna existe\n        serie = df_convertido[col]\n\n        try:\n            if tipo in (\"int\", \"bigint\", \"smallint\", \"tinyint\"):\n                serie_nueva = pd.to_numeric(serie, errors=\"coerce\").astype(\"Int64\")\n\n            elif tipo in (\"decimal\", \"numeric\", \"float\", \"real\", \"money\", \"smallmoney\"):\n                serie_nueva = pd.to_numeric(serie, errors=\"coerce\")\n\n            elif tipo in (\"date\", \"datetime\", \"datetime2\", \"smalldatetime\", \"datetimeoffset\", \"time\"):\n                serie_nueva = pd.to_datetime(serie, errors=\"coerce\")\n\n            elif tipo == \"bit\":\n                def _map_bit(x):\n                    if pd.isna(x):\n                        return None\n                    s = str(x).strip().lower()\n                    if s in (\"1\", \"true\", \"si\", \"sí\", \"y\", \"yes\"):\n                        return 1\n                    if s in (\"0\", \"false\", \"no\", \"n\"):\n                        return 0\n                    return None\n\n                serie_nueva = serie.map(_map_bit).astype(\"Int64\")\n\n            else:\n                # Asumimos tipos de texto (varchar, nvarchar, char, text, etc.)\n                # Si viene NaN, lo dejamos como NaN para que SQL lo reciba como NULL\n                serie_nueva = serie.astype(\"string\")\n\n                if pd.notna(max_len) and max_len is not None and max_len > 0:\n                    serie_nueva = serie_nueva.str.slice(0, int(max_len))\n\n            # -------- Validación de conversión en campos NO NULL --------\n            if tipo in (\n                \"int\", \"bigint\", \"smallint\", \"tinyint\",\n                \"decimal\", \"numeric\", \"float\", \"real\", \"money\", \"smallmoney\",\n                \"date\", \"datetime\", \"datetime2\", \"smalldatetime\", \"datetimeoffset\", \"time\",\n                \"bit\"\n            ):\n                mask_original_no_nulo = serie.notna() & (serie.astype(str).str.strip() != \"\")\n                mask_convertido_nulo = pd.isna(serie_nueva)\n\n                problematicos = df_convertido[mask_original_no_nulo & mask_convertido_nulo]\n\n                if not problematicos.empty and is_nullable == \"NO\":\n                    errores.append(\n                        f\"Columna '{col}' ({tipo}) tiene {len(problematicos)} \"\n                        f\"valores no convertibles y la columna NO admite NULL.\"\n                    )\n\n            df_convertido[col] = serie_nueva\n\n        except Exception as e:\n            errores.append(f\"Error convirtiendo columna '{col}' a tipo {tipo}: {e}\")\n\n    if errores:\n        print(\"⚠️ Se encontraron problemas de conversión de tipos:\")\n        for e in errores:\n            print(\" -\", e)\n        # Si quieres que aún así inserte NULL en lo que no se pudo convertir,\n        # deja esto como solo print. Si quieres que reviente, deja el raise:\n        raise ValueError(\"Errores de conversión de tipos: revisa los mensajes anteriores.\")\n\n    # Ordenar columnas en el mismo orden de la tabla en SQL\n    columnas_finales = schema_sql[\"COLUMN_NAME\"].tolist()\n    df_convertido = df_convertido[columnas_finales]\n\n    return df_convertido\n\n\n# Convertimos df al esquema esperado en SQL\ndf_convertido = convertir_dataframe_a_esquema_sql(df, schema_df)\n\nprint(\"✅ DataFrame convertido a tipos compatibles con SQL.\")\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "74632fac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creando tabla temporal...\n",
            "Insertando datos en tabla temporal...\n",
            "Insertando datos desde temporal hacia tabla destino...\n",
            "Eliminando tabla temporal...\n",
            "✅ Proceso completado: tipos validados y datos cargados en la tabla destino.\n"
          ]
        }
      ],
      "source": [
        "from sqlalchemy import text, event\n\n# ==========================\n# Acelerar inserts en SQL Server (pyodbc)\n# ==========================\n@event.listens_for(engine, \"before_cursor_execute\")\ndef _set_fast_executemany(conn, cursor, statement, parameters, context, executemany):\n    if executemany:\n        cursor.fast_executemany = True\n\n\n# =======================================================\n# 6. CREAR TABLA TEMPORAL Y CARGAR DATOS (CORREGIDO)\n# =======================================================\n\n# Usa nombres con corchetes para evitar líos\ntabla_destino_full  = f\"[{schema_destino}].[{tabla_destino}]\"\ntabla_temporal_full = f\"[{schema_destino}].[{tabla_temporal}]\"\n\nsql_crear_temporal = f\"\"\"\nIF OBJECT_ID(N'{schema_destino}.{tabla_temporal}', 'U') IS NOT NULL\n    DROP TABLE {tabla_temporal_full};\n\nSELECT TOP (0) *\nINTO {tabla_temporal_full}\nFROM {tabla_destino_full};\n\"\"\"\n\nwith engine.begin() as conn:\n    print(\"Creando tabla temporal...\")\n    conn.execute(text(sql_crear_temporal))\n\n    print(\"Insertando datos en tabla temporal...\")\n\n    # ✅ QUITAMOS method=\"multi\" (evita el límite 2100 parámetros)\n    df_convertido.to_sql(\n        name=tabla_temporal,\n        con=conn,\n        schema=schema_destino,\n        if_exists=\"append\",\n        index=False,\n        chunksize=1000\n    )\n\n    print(\"Insertando datos desde temporal hacia tabla destino...\")\n\n    # Columnas desde schema_df (en el mismo orden)\n    columnas = schema_df[\"COLUMN_NAME\"].tolist()\n    columnas_sql = \", \".join(f\"[{c}]\" for c in columnas)\n\n    sql_insert_final = f\"\"\"\n    INSERT INTO {tabla_destino_full} ({columnas_sql})\n    SELECT {columnas_sql}\n    FROM {tabla_temporal_full};\n    \"\"\"\n    conn.execute(text(sql_insert_final))\n\n    print(\"Eliminando tabla temporal...\")\n    conn.execute(text(f\"DROP TABLE {tabla_temporal_full};\"))\n\nprint(\"✅ Proceso completado: tipos validados y datos cargados en la tabla destino.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}