{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01454b6d",
   "metadata": {},
   "source": [
    "## Traer audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "990ee7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haider_bello\\AppData\\Local\\Temp\\ipykernel_39220\\2424318246.py:52: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "2025-12-26 10:40:45,456 - INFO     - âœ… Consulta SQL ejecutada. Registros obtenidos: 253\n",
      "2025-12-26 10:40:56,187 - INFO     - ğŸ” Total archivos de audio encontrados: 3\n",
      "2025-12-26 10:40:56,187 - INFO     - ğŸ“¦ Total archivos copiados: 3\n",
      "2025-12-26 10:40:56,203 - INFO     - ğŸ“Š Archivos copiados por cargo:\n",
      "2025-12-26 10:40:56,204 - INFO     -    AUXILIAR GESTOR VINCULACIONES: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import pyodbc\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# â”€â”€ CONFIGURACIÃ“N â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "RUTA_ORIGEN       = r\"\\\\SRVSFTPFIVE9\\Users\\sftpuser\\recordings\"\n",
    "FECHA_OBJETIVO    = \"12_25_2025\"  # Fecha de carpeta (M_D_YYYY)\n",
    "RUTA_DESTINO_BASE = r\"C:\\prueba_audios\\16-09-2025_real\"\n",
    "\n",
    "# ConexiÃ³n SQL Server\n",
    "DB_SERVER   = \"172.16.1.33\"\n",
    "DB_NAME     = \"CUN_REPOSITORIO\"\n",
    "\n",
    "EXTENSIONES_AUDIO = ['.wav', '.mp3', '.wma']\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)-8s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('monitor_audio.log', encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def cargar_plantilla_sql():\n",
    "    \"\"\"Carga la plantilla desde SQL Server usando Trusted_Connection.\"\"\"\n",
    "    try:\n",
    "        conn = pyodbc.connect(\n",
    "            f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "            f\"SERVER={DB_SERVER};\"\n",
    "            f\"DATABASE={DB_NAME};\"\n",
    "            \"Trusted_Connection=yes;\"\n",
    "        )\n",
    "\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            Identificacion AS IdentificaciÃ³n,\n",
    "            Nombre AS Nombres,\n",
    "            Apellidos AS Apellidos,\n",
    "            NOM_CARG AS [DescripciÃ³n Cargo],\n",
    "            box_mail AS Correo\n",
    "        FROM dbo.Planta_Activa\n",
    "        WHERE NOM_CARG LIKE '%auxi%'\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.read_sql(query, conn)\n",
    "        conn.close()\n",
    "\n",
    "        logging.info(f\"âœ… Consulta SQL ejecutada. Registros obtenidos: {len(df)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al conectar con SQL Server: {e}\")\n",
    "        return {}\n",
    "\n",
    "    if 'Correo' not in df.columns or 'DescripciÃ³n Cargo' not in df.columns:\n",
    "        logging.error(\"La consulta SQL no devuelve columnas 'Correo' y 'DescripciÃ³n Cargo'.\")\n",
    "        return {}\n",
    "\n",
    "    return dict(zip(df['Correo'].str.lower(), df['DescripciÃ³n Cargo']))\n",
    "\n",
    "def obtener_fecha_folder():\n",
    "    if FECHA_OBJETIVO:\n",
    "        mm, dd, yyyy = FECHA_OBJETIVO.split('_')\n",
    "        fecha = datetime(int(yyyy), int(mm), int(dd))\n",
    "    else:\n",
    "        fecha = datetime.now() - timedelta(days=1)\n",
    "    return f\"{fecha.month}_{fecha.day}_{fecha.year}\"\n",
    "\n",
    "def crear_dir(ruta):\n",
    "    Path(ruta).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def es_audio(nombre):\n",
    "    return any(nombre.lower().endswith(ext) for ext in EXTENSIONES_AUDIO)\n",
    "\n",
    "def limpiar_nombre(nombre_archivo):\n",
    "    return nombre_archivo.replace('+', '')\n",
    "\n",
    "def copiar(origen, destino_base, cargo, correo, fecha):\n",
    "    destino_carpeta = os.path.join(destino_base, cargo, correo, fecha)\n",
    "    crear_dir(destino_carpeta)\n",
    "\n",
    "    nombre_archivo_limpio = limpiar_nombre(os.path.basename(origen))\n",
    "    dst = os.path.join(destino_carpeta, nombre_archivo_limpio)\n",
    "\n",
    "    if os.path.exists(dst) and os.path.getsize(dst) == os.path.getsize(origen):\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        shutil.copy2(origen, dst)\n",
    "        return True\n",
    "    except Exception as ex:\n",
    "        logging.error(f\"Error al copiar '{origen}': {ex}\")\n",
    "        return False\n",
    "\n",
    "# <<< CAMBIO: mapeo especial de carpetas â€œno-emailâ€\n",
    "ESPECIALES = {\n",
    "    'cun',\n",
    "    'vinculaciones ob',\n",
    "    'vinculaciones ib',\n",
    "}\n",
    "CARGO_ESPECIAL = 'AUXILIAR GESTOR VINCULACIONES'\n",
    "DOMINIO = '@cun.edu.co'\n",
    "\n",
    "def resolver_correo_y_cargo(asesor_nombre: str, cargo_por_correo: dict) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    - Si la carpeta del asesor es una de las especiales, le agrega @cun.edu.co\n",
    "      y le asigna el cargo AUXILIAR GESTOR VINCULACIONES.\n",
    "    - En caso contrario, intenta buscar el cargo por correo en la plantilla SQL.\n",
    "    \"\"\"\n",
    "    asesor_key = asesor_nombre.strip().lower()\n",
    "    if asesor_key in ESPECIALES:\n",
    "        correo = asesor_key + DOMINIO\n",
    "        cargo = CARGO_ESPECIAL\n",
    "        logging.debug(f\"âš™ï¸ Mapeo especial aplicado: {asesor_nombre} -> {correo} / {cargo}\")\n",
    "        return correo, cargo\n",
    "\n",
    "    # Si ya viene con dominio, se usa tal cual; si no, se deja como estÃ¡ (tu lÃ³gica original)\n",
    "    correo = asesor_key\n",
    "    cargo = cargo_por_correo.get(correo, 'SIN_CARGO_DEFINIDO')\n",
    "    return correo, cargo\n",
    "# >>> FIN CAMBIO\n",
    "\n",
    "def procesar_audios():\n",
    "    FECHA_FOLDER = obtener_fecha_folder()\n",
    "    RUTA_DESTINO = os.path.join(RUTA_DESTINO_BASE, f\"audios {FECHA_FOLDER}\")\n",
    "    \n",
    "    total_encontrados = 0\n",
    "    total_copiados = 0\n",
    "    conteo_por_cargo = defaultdict(int)\n",
    "\n",
    "    # Cargar plantilla desde SQL\n",
    "    CARGO_POR_CORREO = cargar_plantilla_sql()\n",
    "\n",
    "    if not os.path.isdir(RUTA_ORIGEN):\n",
    "        logging.error(f\"No existe ruta origen: {RUTA_ORIGEN}\")\n",
    "        return\n",
    "\n",
    "    for asesor in os.listdir(RUTA_ORIGEN):\n",
    "        carpeta_asesor = os.path.join(RUTA_ORIGEN, asesor)\n",
    "        if not os.path.isdir(carpeta_asesor):\n",
    "            continue\n",
    "\n",
    "        # <<< CAMBIO: resolver correo/cargo con la regla especial\n",
    "        correo, cargo = resolver_correo_y_cargo(asesor, CARGO_POR_CORREO)\n",
    "        # >>> FIN CAMBIO\n",
    "\n",
    "        carpeta_fecha = os.path.join(carpeta_asesor, FECHA_FOLDER)\n",
    "        if not os.path.isdir(carpeta_fecha):\n",
    "            continue\n",
    "\n",
    "        for root, _, files in os.walk(carpeta_fecha):\n",
    "            for archivo in files:\n",
    "                if not es_audio(archivo):\n",
    "                    continue\n",
    "                total_encontrados += 1\n",
    "                ruta_arch = os.path.join(root, archivo)\n",
    "                if copiar(ruta_arch, RUTA_DESTINO, cargo, correo, FECHA_FOLDER):\n",
    "                    total_copiados += 1\n",
    "                    conteo_por_cargo[cargo] += 1\n",
    "\n",
    "    logging.info(f\"ğŸ” Total archivos de audio encontrados: {total_encontrados}\")\n",
    "    logging.info(f\"ğŸ“¦ Total archivos copiados: {total_copiados}\")\n",
    "\n",
    "    # Mostrar conteo por cargo\n",
    "    logging.info(\"ğŸ“Š Archivos copiados por cargo:\")\n",
    "    for cargo, cantidad in conteo_por_cargo.items():\n",
    "        logging.info(f\"   {cargo}: {cantidad}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    procesar_audios()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94326a",
   "metadata": {},
   "source": [
    "## Txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install faster-whisper torch --upgrade\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import threading\n",
    "from queue import Queue\n",
    "from pathlib import Path\n",
    "from faster_whisper import WhisperModel\n",
    "import torch\n",
    "\n",
    "# â”€â”€â”€â”€â”€ RUTAS (AJUSTA) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "INPUT_ROOT = Path(r\"C:\\prueba_audios\\16-09-2025_real\\audios 12_22_2025\\AUXILIAR GESTOR VINCULACIONES\")\n",
    "OUTPUT_DIR = Path(r\"C:\\descargas\\cltiene_nov\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "AUDIO_EXTS = {\".wav\", \".mp3\", \".m4a\", \".flac\", \".ogg\", \".aac\", \".wma\"}\n",
    "\n",
    "# â”€â”€â”€â”€â”€ DETECCIÃ“N GPU / CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "assert DEVICE == \"cuda\", \"Para 90% de uso necesitas GPU. No se detectÃ³ CUDA.\"\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "MODEL_NAME   = \"medium\"\n",
    "COMPUTE_TYPE = \"large-v2\"           # FP16 en GPU = rÃ¡pido\n",
    "BEAM_SIZE    = 5                   # 1 = mÃ¡s veloz\n",
    "LANG         = \"es\"\n",
    "\n",
    "# Estimar cuÃ¡ntas instancias caben en 12 GB (aprox medium FP16 ~4-5 GB)\n",
    "free, total = torch.cuda.mem_get_info()\n",
    "free_gb  = free / (1024**3)\n",
    "total_gb = total / (1024**3)\n",
    "\n",
    "# MÃ¡ximo 3 modelos; si VRAM libre <7.5 GB, usa 2; si >=11 GB, prueba 3\n",
    "MAX_MODELS = 3 if free_gb >= 11 else (2 if free_gb >= 7.5 else 1)\n",
    "print(f\"GPU VRAM libre: {free_gb:.1f} GB / {total_gb:.1f} GB â†’ instancias: {MAX_MODELS}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€ UTILIDADES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def gather_audio_files(root: Path):\n",
    "    for dp, _, files in os.walk(root):\n",
    "        for f in files:\n",
    "            if Path(f).suffix.lower() in AUDIO_EXTS:\n",
    "                yield Path(dp) / f\n",
    "\n",
    "def transcribe_with_model(model: WhisperModel, audio_path: Path, out_dir: Path) -> str:\n",
    "    out_path = out_dir / (audio_path.stem + \".txt\")\n",
    "    if out_path.exists():\n",
    "        return f\"â¡ï¸ {audio_path.name} (ya existe)\"\n",
    "    segments, _ = model.transcribe(\n",
    "        str(audio_path),\n",
    "        language=LANG,\n",
    "        vad_filter=True,\n",
    "        vad_parameters=dict(min_silence_duration_ms=400),\n",
    "        beam_size=BEAM_SIZE,\n",
    "        best_of=1,\n",
    "        temperature=0.0,\n",
    "        without_timestamps=True,\n",
    "        word_timestamps=False,\n",
    "        condition_on_previous_text=True,\n",
    "    )\n",
    "    text = \"\".join(s.text for s in segments).strip()\n",
    "    out_path.write_text(text, encoding=\"utf-8\")\n",
    "    return f\"âœ”ï¸ {audio_path.name} ({len(text)} chars)\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€ POOL DE WORKERS (CADA UNO CON SU MODELO) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def worker_loop(worker_id: int, q: Queue, results: list, lock: threading.Lock):\n",
    "    # Cada worker carga SU propia instancia del modelo (mantiene GPU ocupada)\n",
    "    model = WhisperModel(\n",
    "        MODEL_NAME,\n",
    "        device=\"cuda\",\n",
    "        compute_type=COMPUTE_TYPE,\n",
    "        device_index=0,      # cambia si usas otra GPU\n",
    "        num_workers=1        # hilos internos del modelo (no subir en GPU)\n",
    "    )\n",
    "    while True:\n",
    "        audio_path = q.get()\n",
    "        if audio_path is None:\n",
    "            q.task_done()\n",
    "            break\n",
    "        try:\n",
    "            msg = transcribe_with_model(model, audio_path, OUTPUT_DIR)\n",
    "        except Exception as e:\n",
    "            msg = f\"âŒ {audio_path.name} â†’ {e}\"\n",
    "        with lock:\n",
    "            results.append(msg)\n",
    "            print(msg)\n",
    "        q.task_done()\n",
    "\n",
    "def main():\n",
    "    files = list(gather_audio_files(INPUT_ROOT))\n",
    "    total = len(files)\n",
    "    if total == 0:\n",
    "        print(\"âš ï¸ No se encontraron audios.\")\n",
    "        return\n",
    "\n",
    "    # Ordenar por tamaÃ±o descendente para balancear carga (los largos primero)\n",
    "    files.sort(key=lambda p: p.stat().st_size if p.exists() else 0, reverse=True)\n",
    "\n",
    "    print(f\"ğŸ—‚ï¸  Audios: {total}  Â·  Workers(modelos): {MAX_MODELS}\\n\")\n",
    "\n",
    "    q = Queue(maxsize=MAX_MODELS * 4)  # prefetched items\n",
    "    results, lock = [], threading.Lock()\n",
    "    threads = []\n",
    "\n",
    "    # Lanzar N workers (cada uno con su modelo)\n",
    "    for i in range(MAX_MODELS):\n",
    "        t = threading.Thread(target=worker_loop, args=(i, q, results, lock), daemon=True)\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    # Ingesta en la cola con barra de progreso simple\n",
    "    start = time.time()\n",
    "    for idx, f in enumerate(files, 1):\n",
    "        q.put(f)\n",
    "        if idx % 50 == 0:\n",
    "            elapsed = time.time() - start\n",
    "            done = len(results)\n",
    "            if done:\n",
    "                rate = done / elapsed               # archivos/seg\n",
    "                eta  = (total - done) / rate\n",
    "                print(f\"â³ {done}/{total} Â· {rate*60:.1f} a/min Â· ETA {eta/60:.1f} min\")\n",
    "\n",
    "    # SeÃ±ales de fin\n",
    "    for _ in range(MAX_MODELS):\n",
    "        q.put(None)\n",
    "\n",
    "    q.join()  # esperar a que terminen\n",
    "    \n",
    "    dur = time.time() - start\n",
    "    print(f\"\\nğŸ Listo: {len(results)}/{total} en {dur/60:.1f} min \"\n",
    "          f\"({(total/(dur/60)):0.1f} audios/min aprox)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae175ea",
   "metadata": {},
   "source": [
    "## evaluacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Optional, Tuple, List\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from getpass import getpass\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pyodbc\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RUTAS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "INPUT_TXT_DIR = Path(r\"C:\\descargas\\ventas_audios_16-09-2025_hoy_12_19\")\n",
    "OUTPUT_DIR    = Path(r\"C:\\descargas\\ventas_audios_16-09-2025_hoy_12_191\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FECHA_ANALISIS = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "TIPO = \"llamada\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ OLLAMA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "USE_OLLAMA = True\n",
    "OLLAMA_BASE = \"http://localhost:11434\"\n",
    "OLLAMA_MODEL = \"qwen2.5:7b-instruct\"\n",
    "OLLAMA_TIMEOUT = 180\n",
    "OLLAMA_MAX_RETRIES = 2\n",
    "MAX_OLLAMA_WORKERS = 2  # 1-3 segÃºn tu PC\n",
    "\n",
    "# LLM solo cuando aporta valor:\n",
    "OLLAMA_ONLY_BORDERLINE = True\n",
    "BORDERLINE_MIN = 0.45\n",
    "BORDERLINE_MAX = 0.90\n",
    "\n",
    "# Revisar humano si baja confianza del modelo:\n",
    "REVIEW_MIN_CONF = 0.65\n",
    "\n",
    "# Cache LLM:\n",
    "CACHE_DIR = OUTPUT_DIR / \"_ollama_cache\"\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SQL (EMBEBIDO + AUTO-GUARDADO) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SQL_SERVER   = \"172.16.1.33\"\n",
    "SQL_DATABASE = \"CUN_REPOSITORIO\"\n",
    "SQL_USER     = \"haider_bello\"\n",
    "\n",
    "# OpciÃ³n A (recomendada): dejar None para que lo pida 1 vez y lo guarde\n",
    "SQL_PASSWORD: Optional[str] = None\n",
    "\n",
    "# OpciÃ³n B (NO recomendada): puedes hardcodear aquÃ­ (te lo dejo comentado)\n",
    "# SQL_PASSWORD = r\"TU_PASSWORD_AQUI\"\n",
    "\n",
    "SAVE_SQL_PASSWORD_LOCALLY = True\n",
    "SQL_CONFIG_DIR = Path.home() / \".cun_call_eval\"\n",
    "SQL_CONFIG_DIR.mkdir(exist_ok=True)\n",
    "SQL_CONFIG_FILE = SQL_CONFIG_DIR / \"sql_config.json\"\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DICCIONARIOS (ETAPAS) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "diccionarios_keywords = {\n",
    "    \"saludo\": sorted({\n",
    "        \"alo\",\"hola\",\"ola\",\"ohla\",\"buenos dias\",\"buenas tardes\",\"buenas noches\",\n",
    "        \"saludo\",\"bienvenido\",\"me comunico\",\"le saludo\",\"le puedo ayudar\",\n",
    "        \"en que le puedo servir\",\"soy\",\"me presento\",\"habla con\",\"hablo con\",\n",
    "        \"muchas gracias\",\"con gusto\",\"hasta luego\",\"que tenga un buen dia\"\n",
    "    }),\n",
    "    \"indagacion\": sorted({\n",
    "        \"confirmar\",\"verificar\",\"ubicacion\",\"ciudad\",\"modalidad\",\"programa\",\"edad\",\n",
    "        \"documento\",\"icfes\",\"homologacion\",\"estudios previos\",\"interes\",\n",
    "        \"estas interesado\",\"estas interesada\",\"cuentame\",\"cuÃ©ntame\"\n",
    "    }),\n",
    "    \"programas\": sorted({\n",
    "        \"ingenieria\",\"derecho\",\"administracion\",\"comunicacion social\",\"periodismo\",\n",
    "        \"contaduria\",\"sistemas\",\"industrial\",\"salud\",\"software\",\"mercadeo\",\"publicidad\"\n",
    "    }),\n",
    "    \"argumentacion\": sorted({\n",
    "        \"beca\",\"descuento\",\"financiacion\",\"convenio\",\"virtual\",\"presencial\",\n",
    "        \"flexibilidad\",\"salidas laborales\",\"costo\",\"valor semestre\",\"cuotas\",\n",
    "        \"requisitos\",\"proceso\",\"beneficios\",\"homologar\",\"credito educativo\"\n",
    "    }),\n",
    "    \"objecion\": sorted({\n",
    "        \"muy caro\",\"no tengo tiempo\",\"lo pensare\",\"lo pensarÃ©\",\"duda\",\"que te preocupa\",\n",
    "        \"entiendo\",\"comprendo\",\"opciones de financiacion\",\"plan de pagos\",\n",
    "        \"flexibilidad de horarios\",\"estudia a tu ritmo\"\n",
    "    }),\n",
    "    # cierre incluye tambiÃ©n frases de seguimiento\n",
    "    \"cierre\": sorted({\n",
    "        \"te inscribo\",\"te llamo maÃ±ana\",\"te llamo manana\",\"te contacto maÃ±ana\",\"te contacto manana\",\n",
    "        \"agendamos llamada\",\"agendemos\",\"te confirmo cita\",\"confirmo la cita\",\"quedamos en\",\n",
    "        \"confirmar inscripcion\",\"enviar documentos\",\"realizar pago\",\"matricula\",\"inscripcion\",\n",
    "        \"te envio info\",\"te envÃ­o info\",\"conversemos por whatsapp\",\"link\",\"portal\"\n",
    "    }),\n",
    "}\n",
    "\n",
    "# Score por etapa: mÃ­nimo ocurrencias y peso\n",
    "requisitos_keywords = {\n",
    "    \"saludo\": (1, 1/6),\n",
    "    \"indagacion\": (1, 1/6),\n",
    "    \"programas\": (1, 1/6),\n",
    "    \"argumentacion\": (1, 1/6),\n",
    "    \"objecion\": (1, 1/6),\n",
    "    \"cierre\": (1, 1/6),\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GATILLOS PARA ENTENDER â€œRESULTADOâ€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ANTI_CIERRE_FRASES = [\n",
    "    \"lo voy a pensar\", \"lo pensare\", \"lo pensarÃ©\", \"tengo que pensarlo\", \"tengo que pensarlo mas\",\n",
    "    \"no estoy seguro\", \"no estoy segura\", \"despues\", \"despuÃ©s\", \"mas adelante\", \"mÃ¡s adelante\",\n",
    "    \"no hoy\", \"luego\", \"te aviso\", \"dejame revisar\", \"dÃ©jame revisar\", \"dejame consultarlo\",\n",
    "    \"no puedo ahora\", \"en otro momento\", \"por ahora no\"\n",
    "]\n",
    "\n",
    "# Cierre real (venta)\n",
    "CIERRE_REAL_FRASES = [\n",
    "    \"ya pague\", \"ya paguÃ©\", \"pago hoy\", \"voy a pagar hoy\", \"lo pago hoy\", \"ya hice el pago\",\n",
    "    \"ya me inscribi\", \"ya me inscribÃ­\", \"ya me matricule\", \"ya me matriculÃ©\",\n",
    "    \"quede inscrito\", \"quedÃ© inscrito\", \"quedo inscrita\", \"quedÃ³ inscrita\",\n",
    "    \"matricula realizada\", \"matrÃ­cula realizada\"\n",
    "]\n",
    "\n",
    "# Seguimiento para cierre (tu criterio de efectiva)\n",
    "SEGUIMIENTO_FRASES = [\n",
    "    \"te llamo maÃ±ana\", \"te llamo manana\", \"te marco maÃ±ana\", \"te marco manana\",\n",
    "    \"te contacto maÃ±ana\", \"te contacto manana\", \"te vuelvo a llamar\",\n",
    "    \"agendamos llamada\", \"agendemos\", \"queda agendada\", \"quedo agendada\", \"quedÃ³ agendada\",\n",
    "    \"confirmo la cita\", \"te confirmo cita\", \"quedamos en\", \"nos hablamos\", \"nos hablamos maÃ±ana\",\n",
    "    \"te envÃ­o la informaciÃ³n\", \"te envio la informacion\", \"te envÃ­o el link\", \"te envio el link\",\n",
    "    \"seguimiento\", \"seguimos\", \"continuamos\"\n",
    "]\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ UTILIDADES TEXTO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def leer_txt(path: Path) -> str:\n",
    "    for enc in (\"utf-8\", \"latin-1\", \"cp1252\"):\n",
    "        try:\n",
    "            return path.read_text(encoding=enc, errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "    return \"\"\n",
    "\n",
    "def normalizar_texto(texto: str) -> str:\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "    t = texto.lower()\n",
    "    t = unicodedata.normalize(\"NFKD\", t).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    t = re.sub(r\"[^\\w\\s]\", \" \", t)\n",
    "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
    "\n",
    "def tail_text(texto_norm: str, ratio: float = 0.30) -> str:\n",
    "    if not texto_norm:\n",
    "        return \"\"\n",
    "    n = len(texto_norm)\n",
    "    return texto_norm[int(n * (1 - ratio)) :]\n",
    "\n",
    "def _norm_token(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def contiene_frase(texto_norm: str, frases: List[str]) -> bool:\n",
    "    for f in frases:\n",
    "        if _norm_token(f) in texto_norm:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def compilar_patrones(diccionarios: Dict[str, List[str]]) -> Dict[str, re.Pattern]:\n",
    "    patrones = {}\n",
    "    for cat, claves in diccionarios.items():\n",
    "        claves_norm = sorted({_norm_token(c) for c in claves if c and str(c).strip()})\n",
    "        if not claves_norm:\n",
    "            patrones[cat] = re.compile(r\"^\\b$\")\n",
    "            continue\n",
    "        altern = \"|\".join(re.escape(c) for c in claves_norm)\n",
    "        patrones[cat] = re.compile(rf\"(?<!\\w)({altern})(?!\\w)\", flags=re.IGNORECASE)\n",
    "    return patrones\n",
    "\n",
    "def contar_por_categoria(texto_norm: str, patrones: Dict[str, re.Pattern]) -> Dict[str, int]:\n",
    "    return {cat: len(pat.findall(texto_norm)) for cat, pat in patrones.items()}\n",
    "\n",
    "def score_proceso_reglas(conteos: Dict[str, int]) -> Tuple[float, Dict[str, bool]]:\n",
    "    etapas_ok = {}\n",
    "    score = 0.0\n",
    "    for cat, (minimo, peso) in requisitos_keywords.items():\n",
    "        ok = conteos.get(cat, 0) >= minimo\n",
    "        etapas_ok[cat] = ok\n",
    "        if ok:\n",
    "            score += peso\n",
    "    return round(score, 3), etapas_ok\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ METADATOS DESDE NOMBRE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def extraer_correo(nombre_archivo: str) -> str:\n",
    "    cuerpo = Path(nombre_archivo).stem\n",
    "    m = re.search(r'([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,})', cuerpo)\n",
    "    return (m.group(1) if m else \"\").strip().lower()\n",
    "\n",
    "def extraer_nombre_asesor(nombre_archivo: str) -> str:\n",
    "    cuerpo = Path(nombre_archivo).stem\n",
    "    m = re.search(r\"by\\s+(.+?)@\", cuerpo, flags=re.IGNORECASE)\n",
    "    bruto = m.group(1) if m else cuerpo\n",
    "    limpio = re.sub(r\"\\s{2,}\", \" \", bruto.replace(\"_\", \" \").replace(\"-\", \" \").strip())\n",
    "    return limpio.title() if limpio else \"\"\n",
    "\n",
    "def extraer_celular(nombre_archivo: str) -> str:\n",
    "    m = re.search(r'^(\\+?\\d{10,15})', Path(nombre_archivo).stem)\n",
    "    return m.group(1) if m else \"\"\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SQL PASSWORD AUTO (sin configurar nada) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def load_sql_password() -> str:\n",
    "    global SQL_PASSWORD\n",
    "\n",
    "    if SQL_PASSWORD:\n",
    "        return SQL_PASSWORD\n",
    "\n",
    "    # si hay archivo guardado\n",
    "    if SQL_CONFIG_FILE.exists():\n",
    "        try:\n",
    "            cfg = json.loads(SQL_CONFIG_FILE.read_text(encoding=\"utf-8\"))\n",
    "            pw = (cfg.get(\"SQL_PASSWORD\") or \"\").strip()\n",
    "            if pw:\n",
    "                SQL_PASSWORD = pw\n",
    "                return SQL_PASSWORD\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # pedir una vez\n",
    "    pw = getpass(\"ğŸ” Ingresa tu SQL_PASSWORD (se guardarÃ¡ localmente si estÃ¡ habilitado): \").strip()\n",
    "    if not pw:\n",
    "        raise RuntimeError(\"SQL_PASSWORD vacÃ­o. No puedo conectar a SQL Server.\")\n",
    "    SQL_PASSWORD = pw\n",
    "\n",
    "    if SAVE_SQL_PASSWORD_LOCALLY:\n",
    "        try:\n",
    "            SQL_CONFIG_FILE.write_text(json.dumps({\"SQL_PASSWORD\": pw}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "            print(f\"âœ… Password guardado localmente en: {SQL_CONFIG_FILE}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ No pude guardar el password localmente: {e}\")\n",
    "\n",
    "    return SQL_PASSWORD\n",
    "\n",
    "def cargar_cedulas_por_correo() -> Dict[str, str]:\n",
    "    mapping = {}\n",
    "    pw = load_sql_password()\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = pyodbc.connect(\n",
    "            'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "            f'SERVER={SQL_SERVER};'\n",
    "            f'DATABASE={SQL_DATABASE};'\n",
    "            f'UID={SQL_USER};'\n",
    "            f'PWD={pw};'\n",
    "            'Trusted_Connection=no;'\n",
    "        )\n",
    "        query = \"\"\"\n",
    "            SELECT \n",
    "                CAST(Identificacion AS VARCHAR(64)) AS cedula,\n",
    "                CAST(box_mail AS VARCHAR(320))      AS Correo\n",
    "            FROM dbo.Planta_Activa\n",
    "            WHERE box_mail IS NOT NULL AND LTRIM(RTRIM(box_mail)) <> ''\n",
    "        \"\"\"\n",
    "        df_map = pd.read_sql(query, conn)\n",
    "        df_map['Correo'] = df_map['Correo'].astype(str).str.strip().str.lower()\n",
    "        df_map['cedula'] = df_map['cedula'].astype(str).str.strip()\n",
    "        mapping = dict(zip(df_map['Correo'], df_map['cedula']))\n",
    "        print(f\"ğŸ—‚ï¸ CÃ©dulas cargadas desde SQL: {len(mapping)} correos.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ No se pudo consultar Planta_Activa: {e}\")\n",
    "    finally:\n",
    "        try:\n",
    "            if conn is not None:\n",
    "                conn.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return mapping\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CACHE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def file_hash(path: Path) -> str:\n",
    "    h = hashlib.sha1()\n",
    "    h.update(str(path).encode(\"utf-8\"))\n",
    "    try:\n",
    "        st = path.stat()\n",
    "        h.update(str(st.st_mtime_ns).encode(\"utf-8\"))\n",
    "        h.update(str(st.st_size).encode(\"utf-8\"))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return h.hexdigest()[:16]\n",
    "\n",
    "def cache_path_for_txt(txt_path: Path) -> Path:\n",
    "    return CACHE_DIR / f\"{txt_path.stem}__{file_hash(txt_path)}.json\"\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ OLLAMA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def smart_trim_text(text: str, max_chars: int = 12000) -> str:\n",
    "    text = (text or \"\").strip()\n",
    "    if len(text) <= max_chars:\n",
    "        return text\n",
    "    head = text[: int(max_chars * 0.7)]\n",
    "    tail = text[-int(max_chars * 0.3):]\n",
    "    return head + \"\\n...\\n\" + tail\n",
    "\n",
    "def _extract_json_loose(s: str) -> Optional[dict]:\n",
    "    if not s:\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        pass\n",
    "    m = re.search(r\"\\{.*\\}\", s, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(m.group(0))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def ollama_chat_json(system: str, user: str) -> dict:\n",
    "    last_err = None\n",
    "\n",
    "    chat_url = f\"{OLLAMA_BASE}/api/chat\"\n",
    "    payload_chat = {\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"messages\": [{\"role\":\"system\",\"content\":system},{\"role\":\"user\",\"content\":user}],\n",
    "        \"stream\": False,\n",
    "        \"format\": \"json\",\n",
    "        \"options\": {\"temperature\": 0.1, \"num_ctx\": 8192}\n",
    "    }\n",
    "\n",
    "    for attempt in range(1, OLLAMA_MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = requests.post(chat_url, json=payload_chat, timeout=OLLAMA_TIMEOUT)\n",
    "            if r.status_code != 200:\n",
    "                raise RuntimeError(f\"chat HTTP {r.status_code}: {r.text[:250]}\")\n",
    "            data = r.json()\n",
    "            content = (data.get(\"message\") or {}).get(\"content\", \"\")\n",
    "            parsed = _extract_json_loose(content)\n",
    "            if not parsed:\n",
    "                raise ValueError(f\"No parse JSON (chat). Resp: {content[:200]}\")\n",
    "            return parsed\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(1.2 * attempt)\n",
    "\n",
    "    gen_url = f\"{OLLAMA_BASE}/api/generate\"\n",
    "    payload_gen = {\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"prompt\": system + \"\\n\\n\" + user,\n",
    "        \"stream\": False,\n",
    "        \"format\": \"json\",\n",
    "        \"options\": {\"temperature\": 0.1, \"num_ctx\": 8192}\n",
    "    }\n",
    "    for attempt in range(1, OLLAMA_MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = requests.post(gen_url, json=payload_gen, timeout=OLLAMA_TIMEOUT)\n",
    "            if r.status_code != 200:\n",
    "                raise RuntimeError(f\"generate HTTP {r.status_code}: {r.text[:250]}\")\n",
    "            data = r.json()\n",
    "            content = data.get(\"response\", \"\")\n",
    "            parsed = _extract_json_loose(content)\n",
    "            if not parsed:\n",
    "                raise ValueError(f\"No parse JSON (generate). Resp: {content[:200]}\")\n",
    "            return parsed\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(1.2 * attempt)\n",
    "\n",
    "    raise RuntimeError(f\"Ollama fallÃ³: {last_err}\")\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Â¿CUÃNDO LLAMAR AL LLM? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def should_call_ollama(score_proc: float, texto_norm: str, conteos: Dict[str, int]) -> Tuple[bool, str]:\n",
    "    ttail = tail_text(texto_norm, ratio=0.30)\n",
    "\n",
    "    anti = contiene_frase(ttail, ANTI_CIERRE_FRASES)\n",
    "    hay_cierre = conteos.get(\"cierre\", 0) > 0 or contiene_frase(ttail, [\"pago\", \"matricula\", \"inscripcion\", \"portal\", \"link\"])\n",
    "    hay_seguimiento = contiene_frase(ttail, SEGUIMIENTO_FRASES)\n",
    "\n",
    "    # Si hay indecisiÃ³n al final pero tambiÃ©n hay cierre/seguimiento mencionado => el LLM aclara si quedÃ³ seguimiento real\n",
    "    if anti and (hay_cierre or hay_seguimiento):\n",
    "        return True, \"contradiccion_indecision_vs_cierre_seguimiento\"\n",
    "\n",
    "    # anti-cierre al final => LLM decide si se salvÃ³ con seguimiento\n",
    "    if anti:\n",
    "        return True, \"anti_cierre_en_final\"\n",
    "\n",
    "    # si hay seguimiento/cierre pero ambiguo => LLM ayuda (muchas veces el diccionario marca cierre pero no estÃ¡ confirmado)\n",
    "    if (hay_cierre or hay_seguimiento) and score_proc >= 0.75:\n",
    "        return True, \"validar_resultado_cierre_o_seguimiento\"\n",
    "\n",
    "    # borderline\n",
    "    if OLLAMA_ONLY_BORDERLINE and (BORDERLINE_MIN <= score_proc <= BORDERLINE_MAX):\n",
    "        return True, \"borderline_score\"\n",
    "\n",
    "    if not OLLAMA_ONLY_BORDERLINE:\n",
    "        return True, \"modo_llm_todos\"\n",
    "\n",
    "    return False, \"no_aplica\"\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM: EVALUAR PROCESO + RESULTADO (CIERRE O SEGUIMIENTO) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def evaluar_llm(texto_original: str, conteos: Dict[str, int], score_proc: float, etapas_ok: Dict[str, bool]) -> Dict[str, Any]:\n",
    "    system = (\n",
    "        \"Eres auditor experto de calidad de llamadas de admisiones (CUN). \"\n",
    "        \"EvalÃºas PROCESO (etapas) y RESULTADO (CIERRE o SEGUIMIENTO para cerrar). \"\n",
    "        \"Responde SOLO en JSON vÃ¡lido, sin markdown, sin texto adicional.\"\n",
    "    )\n",
    "\n",
    "    user_obj = {\n",
    "        \"definiciones\": {\n",
    "            \"proceso\": (\n",
    "                \"Etapas: saludo/presentaciÃ³n, indagaciÃ³n (necesidad+datos), programas/fit, \"\n",
    "                \"argumentaciÃ³n (valor+costos/financiaciÃ³n), objeciones (si aparecen) y cierre.\"\n",
    "            ),\n",
    "            \"resultado\": (\n",
    "                \"La llamada es EFECTIVA si hay: \"\n",
    "                \"(A) CIERRE de venta (matrÃ­cula/inscripciÃ³n/pago confirmado o intenciÃ³n explÃ­cita inmediata) \"\n",
    "                \"o (B) SEGUIMIENTO claro para cerrar (prÃ³xima llamada/agendamiento/compromiso de contacto) con consentimiento del cliente. \"\n",
    "                \"Si el cliente termina en 'lo pienso' sin seguimiento pactado, entonces NO hay resultado.\"\n",
    "            )\n",
    "        },\n",
    "        \"datos_reglas\": {\n",
    "            \"conteos_diccionarios\": conteos,\n",
    "            \"score_proceso_reglas\": score_proc,\n",
    "            \"etapas_ok_reglas\": etapas_ok\n",
    "        },\n",
    "        \"transcripcion\": smart_trim_text(texto_original, 12000),\n",
    "        \"salida_esperada\": {\n",
    "            \"proceso\": {\n",
    "                \"etapas\": {\n",
    "                    \"saludo\": {\"presente\": True, \"evidencia\": \"frase literal corta\"},\n",
    "                    \"indagacion\": {\"presente\": True, \"evidencia\": \"frase literal corta\"},\n",
    "                    \"programas\": {\"presente\": True, \"evidencia\": \"frase literal corta\"},\n",
    "                    \"argumentacion\": {\"presente\": True, \"evidencia\": \"frase literal corta\"},\n",
    "                    \"objecion\": {\"presente\": True, \"evidencia\": \"frase literal corta\"},\n",
    "                    \"cierre\": {\"presente\": True, \"evidencia\": \"frase literal corta\"}\n",
    "                }\n",
    "            },\n",
    "            \"resultado\": {\n",
    "                \"tipo\": \"cierre|seguimiento|ninguno\",\n",
    "                \"confirmado\": True,\n",
    "                \"evidencia\": \"frase literal corta\"\n",
    "            },\n",
    "            \"score_resultado\": 0.0,\n",
    "            \"efectiva\": 0,\n",
    "            \"sentimiento_cliente\": \"positivo|neutro|negativo\",\n",
    "            \"confianza\": 0.0,\n",
    "            \"razones\": [\"max 5\"],\n",
    "            \"mejoras\": [\"max 5\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    parsed = ollama_chat_json(system=system, user=json.dumps(user_obj, ensure_ascii=False))\n",
    "\n",
    "    # saneo\n",
    "    parsed.setdefault(\"score_resultado\", 0.0)\n",
    "    parsed.setdefault(\"confianza\", 0.5)\n",
    "    parsed.setdefault(\"sentimiento_cliente\", \"neutro\")\n",
    "    parsed.setdefault(\"razones\", [])\n",
    "    parsed.setdefault(\"mejoras\", [])\n",
    "    parsed.setdefault(\"resultado\", {})\n",
    "    parsed.setdefault(\"proceso\", {})\n",
    "    parsed.setdefault(\"efectiva\", 0)\n",
    "\n",
    "    try:\n",
    "        parsed[\"score_resultado\"] = float(parsed.get(\"score_resultado\", 0.0))\n",
    "    except Exception:\n",
    "        parsed[\"score_resultado\"] = 0.0\n",
    "\n",
    "    try:\n",
    "        parsed[\"confianza\"] = float(parsed.get(\"confianza\", 0.5))\n",
    "    except Exception:\n",
    "        parsed[\"confianza\"] = 0.5\n",
    "\n",
    "    try:\n",
    "        parsed[\"efectiva\"] = int(parsed.get(\"efectiva\", 0))\n",
    "    except Exception:\n",
    "        parsed[\"efectiva\"] = 0\n",
    "\n",
    "    res = parsed.get(\"resultado\") or {}\n",
    "    if not isinstance(res, dict):\n",
    "        res = {}\n",
    "    res.setdefault(\"tipo\", \"ninguno\")\n",
    "    res.setdefault(\"confirmado\", False)\n",
    "    res.setdefault(\"evidencia\", \"\")\n",
    "    parsed[\"resultado\"] = res\n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RESULTADO SIN LLM (CONSERVADOR) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def estimar_score_resultado_sin_llm(texto_norm: str) -> Tuple[float, str]:\n",
    "    ttail = tail_text(texto_norm, ratio=0.30)\n",
    "    anti = contiene_frase(ttail, ANTI_CIERRE_FRASES)\n",
    "\n",
    "    cierre_real = contiene_frase(ttail, CIERRE_REAL_FRASES)\n",
    "    seguimiento = contiene_frase(ttail, SEGUIMIENTO_FRASES)\n",
    "\n",
    "    # Si hay anti-cierre pero hay seguimiento pactado => resultado medio (porque sÃ­ hay plan de cierre)\n",
    "    if anti and seguimiento:\n",
    "        return 0.65, \"regla_seguimiento_a_pesar_de_indecision\"\n",
    "\n",
    "    if cierre_real and not anti:\n",
    "        return 0.85, \"regla_cierre_real\"\n",
    "\n",
    "    if seguimiento and not anti:\n",
    "        return 0.70, \"regla_seguimiento\"\n",
    "\n",
    "    if anti:\n",
    "        return 0.15, \"regla_anti_cierre\"\n",
    "\n",
    "    return 0.30, \"regla_sin_evidencia_resultado\"\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ETIQUETA FINAL (TU DEFINICIÃ“N) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def etiqueta_final(score_proceso: float, score_resultado: float) -> str:\n",
    "    # efectiva = proceso sÃ³lido + resultado (cierre o seguimiento)\n",
    "    if score_proceso >= 0.75 and score_resultado >= 0.70:\n",
    "        return \"efectiva\"\n",
    "    # buena pero no cerrada = buena ejecuciÃ³n sin resultado suficiente\n",
    "    if score_proceso >= 0.75 and score_resultado < 0.70:\n",
    "        return \"buena_no_cerrada\"\n",
    "    return \"no_efectiva\"\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ANALIZAR 1 TXT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def analizar_un_txt(p: Path, patrones: Dict[str, re.Pattern], cedulas_sql: Dict[str, str]) -> Dict[str, Any]:\n",
    "    texto = leer_txt(p)\n",
    "    texto_norm = normalizar_texto(texto)\n",
    "\n",
    "    conteos = contar_por_categoria(texto_norm, patrones)\n",
    "    score_proc, etapas_ok = score_proceso_reglas(conteos)\n",
    "\n",
    "    correo  = extraer_correo(p.name)\n",
    "    asesor  = extraer_nombre_asesor(p.name)\n",
    "    celular = extraer_celular(p.name)\n",
    "    cedula  = cedulas_sql.get(correo, \"\") if correo else \"\"\n",
    "\n",
    "    tamano_B  = p.stat().st_size if p.exists() else 0\n",
    "    palabras  = len(texto_norm.split()) if texto_norm else 0\n",
    "    oraciones = len(re.findall(r\"[.!?]+\", texto)) if texto else 0\n",
    "\n",
    "    llm_usado = False\n",
    "    llm_motivo = \"\"\n",
    "    llm_conf = \"\"\n",
    "    llm_sent = \"\"\n",
    "    llm_razones = \"\"\n",
    "    llm_mejoras = \"\"\n",
    "    res_tipo = \"\"\n",
    "    res_conf = \"\"\n",
    "    res_evid = \"\"\n",
    "    evidencias_etapas = {}\n",
    "\n",
    "    score_res = 0.0\n",
    "    res_fuente = \"regla\"\n",
    "    revisar_humano = False\n",
    "\n",
    "    if USE_OLLAMA:\n",
    "        call, motivo = should_call_ollama(score_proc, texto_norm, conteos)\n",
    "        if call:\n",
    "            llm_usado = True\n",
    "            llm_motivo = motivo\n",
    "\n",
    "            cpath = cache_path_for_txt(p)\n",
    "            llm = None\n",
    "            if cpath.exists():\n",
    "                try:\n",
    "                    llm = json.loads(cpath.read_text(encoding=\"utf-8\"))\n",
    "                except Exception:\n",
    "                    llm = None\n",
    "\n",
    "            if llm is None:\n",
    "                llm = evaluar_llm(texto_original=texto, conteos=conteos, score_proc=score_proc, etapas_ok=etapas_ok)\n",
    "                try:\n",
    "                    cpath.write_text(json.dumps(llm, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            score_res = float(llm.get(\"score_resultado\", 0.0))\n",
    "            res_fuente = \"llm\"\n",
    "\n",
    "            llm_conf = llm.get(\"confianza\", \"\")\n",
    "            llm_sent = llm.get(\"sentimiento_cliente\", \"\")\n",
    "            llm_razones = \"; \".join((llm.get(\"razones\") or [])[:5])\n",
    "            llm_mejoras = \"; \".join((llm.get(\"mejoras\") or [])[:5])\n",
    "\n",
    "            res = llm.get(\"resultado\") or {}\n",
    "            res_tipo = str(res.get(\"tipo\", \"ninguno\"))\n",
    "            res_conf = str(bool(res.get(\"confirmado\", False)))\n",
    "            res_evid = str(res.get(\"evidencia\", \"\"))[:220]\n",
    "\n",
    "            proc = llm.get(\"proceso\") or {}\n",
    "            etapas = (proc.get(\"etapas\") if isinstance(proc, dict) else {}) or {}\n",
    "            for k in [\"saludo\",\"indagacion\",\"programas\",\"argumentacion\",\"objecion\",\"cierre\"]:\n",
    "                v = etapas.get(k, {}) if isinstance(etapas, dict) else {}\n",
    "                if isinstance(v, dict):\n",
    "                    evidencias_etapas[k] = {\n",
    "                        \"presente\": bool(v.get(\"presente\", False)),\n",
    "                        \"evidencia\": str(v.get(\"evidencia\", \"\"))[:180]\n",
    "                    }\n",
    "\n",
    "            # marcar revisiÃ³n humana por baja confianza\n",
    "            try:\n",
    "                if float(llm_conf) < REVIEW_MIN_CONF:\n",
    "                    revisar_humano = True\n",
    "            except Exception:\n",
    "                revisar_humano = True\n",
    "\n",
    "        else:\n",
    "            score_res, res_fuente = estimar_score_resultado_sin_llm(texto_norm)\n",
    "\n",
    "    else:\n",
    "        score_res, res_fuente = estimar_score_resultado_sin_llm(texto_norm)\n",
    "\n",
    "    label = etiqueta_final(score_proc, score_res)\n",
    "\n",
    "    row = {\n",
    "        \"correo\": correo,\n",
    "        \"cedula_asesor\": cedula,\n",
    "        \"asesor\": asesor,\n",
    "        \"asesor_corto\": asesor,\n",
    "        \"fecha\": FECHA_ANALISIS,\n",
    "\n",
    "        \"saludo\": conteos.get(\"saludo\", 0),\n",
    "        \"indagacion\": conteos.get(\"indagacion\", 0),\n",
    "        \"programas\": conteos.get(\"programas\", 0),\n",
    "        \"argumentacion\": conteos.get(\"argumentacion\", 0),\n",
    "        \"objecion\": conteos.get(\"objecion\", 0),\n",
    "        \"cierre\": conteos.get(\"cierre\", 0),\n",
    "\n",
    "        \"score_proceso\": score_proc,\n",
    "        \"score_resultado\": round(float(score_res), 3),\n",
    "        \"resultado_fuente\": res_fuente,\n",
    "\n",
    "        \"etiqueta_final\": label,\n",
    "        \"revisar_humano\": \"1\" if revisar_humano else \"0\",\n",
    "\n",
    "        \"llm_usado\": \"1\" if llm_usado else \"0\",\n",
    "        \"llm_motivo\": llm_motivo,\n",
    "        \"llm_confianza\": llm_conf,\n",
    "        \"llm_sentimiento_cliente\": llm_sent,\n",
    "\n",
    "        \"resultado_tipo\": res_tipo,\n",
    "        \"resultado_confirmado\": res_conf,\n",
    "        \"resultado_evidencia\": res_evid,\n",
    "\n",
    "        \"llm_razones\": llm_razones,\n",
    "        \"llm_mejoras\": llm_mejoras,\n",
    "\n",
    "        \"palabras\": palabras,\n",
    "        \"oraciones\": oraciones,\n",
    "        \"archivo\": p.name,\n",
    "        \"tamano_B\": tamano_B,\n",
    "        \"celular\": celular,\n",
    "        \"tipo\": TIPO,\n",
    "    }\n",
    "\n",
    "    for k in [\"saludo\",\"indagacion\",\"programas\",\"argumentacion\",\"objecion\",\"cierre\"]:\n",
    "        if k in evidencias_etapas:\n",
    "            row[f\"llm_etapa_{k}\"] = str(evidencias_etapas[k].get(\"presente\", False))\n",
    "            row[f\"llm_evid_{k}\"] = evidencias_etapas[k].get(\"evidencia\", \"\")\n",
    "        else:\n",
    "            row[f\"llm_etapa_{k}\"] = \"\"\n",
    "            row[f\"llm_evid_{k}\"] = \"\"\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MAIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def analizar_txts_y_exportar():\n",
    "    cedulas_sql = cargar_cedulas_por_correo()\n",
    "\n",
    "    txt_files = list(INPUT_TXT_DIR.rglob(\"*.txt\"))\n",
    "    if not txt_files:\n",
    "        raise RuntimeError(f\"No encontrÃ© .txt en: {INPUT_TXT_DIR}\")\n",
    "\n",
    "    patrones = compilar_patrones(diccionarios_keywords)\n",
    "\n",
    "    workers = MAX_OLLAMA_WORKERS if USE_OLLAMA else min(8, os.cpu_count() or 4)\n",
    "\n",
    "    filas = []\n",
    "    start = time.time()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=workers) as ex:\n",
    "        futs = [ex.submit(analizar_un_txt, p, patrones, cedulas_sql) for p in txt_files]\n",
    "        for i, f in enumerate(as_completed(futs), 1):\n",
    "            try:\n",
    "                filas.append(f.result())\n",
    "            except Exception as e:\n",
    "                filas.append({\"archivo\": \"ERROR\", \"llm_razones\": str(e)})\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Procesados: {i}/{len(txt_files)}\")\n",
    "\n",
    "    df = pd.DataFrame(filas)\n",
    "\n",
    "    cols = [\n",
    "        \"correo\",\"cedula_asesor\",\"asesor\",\"asesor_corto\",\"fecha\",\n",
    "        \"saludo\",\"indagacion\",\"programas\",\"argumentacion\",\"objecion\",\"cierre\",\n",
    "        \"score_proceso\",\"score_resultado\",\"resultado_fuente\",\n",
    "        \"etiqueta_final\",\"revisar_humano\",\n",
    "        \"llm_usado\",\"llm_motivo\",\"llm_confianza\",\"llm_sentimiento_cliente\",\n",
    "        \"resultado_tipo\",\"resultado_confirmado\",\"resultado_evidencia\",\n",
    "        \"llm_razones\",\"llm_mejoras\",\n",
    "        \"palabras\",\"oraciones\",\"archivo\",\"tamano_B\",\"celular\",\"tipo\",\n",
    "        \"llm_etapa_saludo\",\"llm_evid_saludo\",\n",
    "        \"llm_etapa_indagacion\",\"llm_evid_indagacion\",\n",
    "        \"llm_etapa_programas\",\"llm_evid_programas\",\n",
    "        \"llm_etapa_argumentacion\",\"llm_evid_argumentacion\",\n",
    "        \"llm_etapa_objecion\",\"llm_evid_objecion\",\n",
    "        \"llm_etapa_cierre\",\"llm_evid_cierre\",\n",
    "    ]\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = \"\"\n",
    "    df = df[cols]\n",
    "\n",
    "    base = f\"Ventas_Evaluacion_Robusta_{datetime.now().strftime('%Y-%m-%d')}\"\n",
    "    xlsx = OUTPUT_DIR / f\"{base}.xlsx\"\n",
    "    csv  = OUTPUT_DIR / f\"{base}.csv\"\n",
    "\n",
    "    try:\n",
    "        df.to_excel(xlsx, index=False)\n",
    "        print(f\"âœ… Excel generado: {xlsx}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ No se pudo escribir XLSX ({e}). Guardando CSVâ€¦\")\n",
    "        df.to_csv(csv, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"âœ… CSV generado: {csv}\")\n",
    "\n",
    "    dt = round(time.time() - start, 1)\n",
    "    print(\"\\nResumen etiqueta_final:\")\n",
    "    print(df[\"etiqueta_final\"].value_counts(dropna=False))\n",
    "    print(f\"\\nâ±ï¸ Tiempo: {dt}s | Archivos: {len(df)} | Cache: {CACHE_DIR}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analizar_txts_y_exportar()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
